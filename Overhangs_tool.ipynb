{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c7af2b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "from pandas import DataFrame\n",
    "from numpy import insert\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "from random import sample\n",
    "from random import uniform\n",
    "from time import perf_counter\n",
    "from re import finditer\n",
    "\n",
    "\n",
    "class Tools:\n",
    "    \n",
    "    \"\"\"This is a class for the tools before designing overhangs\n",
    "    \n",
    "    Tools class is the preparations of designing overhangs. It contains a property \n",
    "    of DNA_codons, Ecoli_codon_bias; general attributes of modules, files,\n",
    "    junc_aa_num, scores_file, dna_files, and restriction_file; functions of\n",
    "    find_sequence, find_junctions, self_score, overall_score, find_position,\n",
    "    most_least_common_codons, find_primerand, and seq_bias.\n",
    "    \n",
    "    Attributes:\n",
    "        modules: a list of module names\n",
    "        files: a string of protein filenames \n",
    "        junc_aa_num: an int of the number of amino acid residues\n",
    "        scores_file: a table of overhang scores\n",
    "        dna_files: a string of dna filenames\n",
    "        restriction_file: a string of restriction filenames\n",
    "    \"\"\"\n",
    "    \n",
    "    DNA_codons = {\"A\":[\"GCG\",\"GCA\",\"GCC\",\"GCT\"],\n",
    "                  \"P\":[\"CCG\",\"CCA\",\"CCC\",\"CCT\"],\n",
    "                  \"C\":[\"TGC\",\"TGT\"],\n",
    "                  \"Q\":[\"CAG\",\"CAA\"],\n",
    "                  \"D\":[\"GAC\",\"GAT\"],\n",
    "                  \"E\":[\"GAG\",\"GAA\"],\n",
    "                  \"F\":[\"TTC\",\"TTT\"],\n",
    "                  \"R\":[\"CGG\",\"CGA\",\"CGC\",\"CGT\",\"AGG\",\"AGA\"],\n",
    "                  \"G\":[\"GGG\",\"GGA\",\"GGC\",\"GGT\"],\n",
    "                  \"H\":[\"CAC\",\"CAT\"],\n",
    "                  \"S\":[\"TCG\",\"TCA\",\"TCC\",\"TCT\",\"AGC\",\"AGT\"],\n",
    "                  \"I\":[\"ATA\",\"ATC\",\"ATT\"],\n",
    "                  \"T\":[\"ACG\",\"ACA\",\"ACC\",\"ACT\"],\n",
    "                  \"K\":[\"AAG\",\"AAA\"],\n",
    "                  \"L\":[\"TTG\",\"TTA\",\"CTG\",\"CTA\",\"CTC\",\"CTT\"],\n",
    "                  \"V\":[\"GTA\",\"GTC\",\"GTT\",\"GTG\"],\n",
    "                  \"W\":[\"TGG\"],\n",
    "                  \"Y\":[\"TAC\",\"TAT\"],\n",
    "                  \"M\":[\"ATG\"],\n",
    "                  \"N\":[\"AAC\",\"AAT\"],\n",
    "                  \"Stop\":[\"TAA\",\"TAG\",\"TGA\"]\n",
    "                  }\n",
    "    \n",
    "    Ecoli_codon_bias = {'GGG':0.15, 'GGA':0.11, 'GGT':0.34, 'GGC':0.40,\n",
    "                        'GAG':0.31, 'GAA':0.69, 'GAT':0.63, 'GAC':0.37,\n",
    "                        'GTG':0.37, 'GTA':0.15, 'GTT':0.26, 'GTC':0.22,\n",
    "                        'GCG':0.36, 'GCA':0.21, 'GCT':0.16, 'GCC':0.27,\n",
    "                        'AGG':0.02, 'AGA':0.04, 'CGG':0.10, 'CGA':0.06,\n",
    "                        'CGT':0.38, 'CGC':0.40, 'AAG':0.23, 'AAA':0.77,\n",
    "                        'AAT':0.45, 'AAC':0.55, 'ATG':1.00, 'ATA':0.07,\n",
    "                        'ATT':0.51, 'ATC':0.42, 'ACG':0.27, 'ACA':0.13,\n",
    "                        'ACT':0.17, 'ACC':0.44, 'TGG':1.00, 'TGT':0.45,\n",
    "                        'TGC':0.55, 'TAG':0.07, 'TAA':0.64, 'TGA':0.29,\n",
    "                        'TAT':0.57, 'TAC':0.43, 'TTT':0.57, 'TTC':0.43,\n",
    "                        'AGT':0.15, 'AGC':0.28, 'TCG':0.15, 'TCA':0.12,\n",
    "                        'TCT':0.15, 'TCC':0.15, 'CAG':0.65, 'CAA':0.35,\n",
    "                        'CAT':0.57, 'CAC':0.43, 'TTG':0.13, 'TTA':0.13,\n",
    "                        'CTG':0.50, 'CTA':0.04, 'CTT':0.10, 'CTC':0.10,\n",
    "                        'CCG':0.52, 'CCA':0.19, 'CCT':0.16, 'CCC':0.12\n",
    "                        }\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 modules, \n",
    "                 files,\n",
    "                 junc_aa_num,\n",
    "                 scores_file,\n",
    "                 dna_files,\n",
    "                 restriction_file\n",
    "                 ):\n",
    "        \"\"\"Initialize Tools class\n",
    "        \n",
    "        Input contains list and str\n",
    "        \n",
    "        Args:\n",
    "            modules(list): module names; example is ('#1: D14_C_chain_A','#2: D14_N_chain_A','#3: D18_C_chain_A')\n",
    "            files(str): protein filenames; example is \"example_protein_modules.fasta\\n\"\n",
    "            junc_aa_num(int): the number of amino acid residues for each junction; example is '2+2'\n",
    "            scores_file(str): score table filename; example is '18h_37C'\n",
    "            dna_files(str): dna filenames; example is \"example_DNA_modules.fasta\\n\"\n",
    "            restriction_file(str): restriction site filenames; example is \"example_restrictions.fasta\\n\"\n",
    "        \"\"\"\n",
    "        self.modules = list(i.split(': ')[1] for i in modules)\n",
    "        self.files = files\n",
    "        self.junc_aa_num = junc_aa_num\n",
    "        self.junc_aa_sum = sum(list(map(int, junc_aa_num.split('+'))))\n",
    "        self.scores = read_excel(f\"{scores_file}.xlsx\")\n",
    "        \n",
    "        #save the ligation frequency into a dictionary, the keys are coordinates(two 4bp overhangs)\n",
    "        scores_overall = {}\n",
    "        scores_overhang_axis = self.scores.set_index(\"Overhang\", inplace=False)\n",
    "        SIV = scores_overhang_axis.index.values\n",
    "        SCV = scores_overhang_axis.columns.values\n",
    "        for s1 in SIV:\n",
    "            for s2 in SCV: #determine one pair of overhangs in the table\n",
    "                scores_overall[(s1,s2)] = scores_overhang_axis[s1][s2]\n",
    "        self.scores_overall = scores_overall\n",
    "        \n",
    "        #save the complementary ligation frequency into a dictionary, the keys are x-axis(one 4bp overhangs)\n",
    "        scores_self = {}\n",
    "        scores_number_axis = DataFrame(insert(self.scores.values, 0, values=self.scores.columns, axis=0))\n",
    "        for x in scores_number_axis.index.values:\n",
    "            for y in scores_number_axis.index.values:\n",
    "                if (x==y) & (x!=0):\n",
    "                    f = scores_number_axis.loc[x,y]\n",
    "                    s = scores_number_axis.loc[0,x]\n",
    "                    scores_self[s] = f #grab all diagnal scores from the excel\n",
    "        self.scores_self = scores_self\n",
    "        \n",
    "        #save the maximum ligation frequency in the score table\n",
    "        max_self_score = max(scores_self.values())\n",
    "        self.max_self_score = max_self_score\n",
    "        \n",
    "        #read and save protein files into a dictionary\n",
    "        module_protein = {}\n",
    "        file_list = files.split(\"\\n\")\n",
    "        while \"\" in file_list:\n",
    "            file_list.remove(\"\")\n",
    "        for f in file_list:\n",
    "            module_lib = open(f) #open files\n",
    "            dic={}\n",
    "            for line in module_lib:\n",
    "                if line.startswith('>'):\n",
    "                    name=line.replace('>','').strip()\n",
    "                    dic[name]=''\n",
    "                else:\n",
    "                    dic[name]+=line.replace('\\n','').strip()  #distribute names to keys and sequences to values\n",
    "            module_lib.close()\n",
    "            module_protein = dict(module_protein, **dic)\n",
    "        self.module_protein = module_protein\n",
    "        \n",
    "        #read and save dna files into a dictionary\n",
    "        module_dna = {}\n",
    "        dna_file_list = dna_files.split(\"\\n\")\n",
    "        while \"\" in dna_file_list:\n",
    "            dna_file_list.remove(\"\")\n",
    "        for f in dna_file_list:\n",
    "            module_lib = open(f) #open files\n",
    "            dic={}\n",
    "            for line in module_lib:\n",
    "                if line.startswith('>'):\n",
    "                    name=line.replace('>','').strip()\n",
    "                    dic[name]=''\n",
    "                else:\n",
    "                    dic[name]+=line.replace('\\n','').strip()  #distribute names to keys and sequences to values\n",
    "            module_lib.close()\n",
    "            module_dna = dict(module_dna, **dic)\n",
    "        self.module_dna = module_dna\n",
    "        \n",
    "        #read and save restriction site files into a dictionary\n",
    "        enzyme_site = {}\n",
    "        restriction_file_list = restriction_file.split(\"\\n\")\n",
    "        while \"\" in restriction_file_list:\n",
    "            restriction_file_list.remove(\"\")\n",
    "        for f in restriction_file_list:\n",
    "            module_lib = open(f) #open files\n",
    "            dic={}\n",
    "            for line in module_lib:\n",
    "                if line.startswith('>'):\n",
    "                    name=line.replace('>','').strip()\n",
    "                    dic[name]=''\n",
    "                else:\n",
    "                    dic[name]+=line.replace('\\n','').strip()  #give names to keys and sequences to values\n",
    "            module_lib.close()\n",
    "            enzyme_site = dict(enzyme_site, **dic)\n",
    "        self.enzyme_site = enzyme_site\n",
    "            \n",
    "    def find_sequence(self, database):\n",
    "        \"\"\"This is a sequence searching function\n",
    "        \n",
    "        Search the sequences in specified file for the modules\n",
    "        \n",
    "        Args:\n",
    "            database(dict): a dictionary of modules and sequences\n",
    "        \n",
    "        Returns:\n",
    "            a dictionary where keys are module names\n",
    "            and values are sequeneces\n",
    "        \"\"\"\n",
    "        seq = {}\n",
    "        i = 1\n",
    "        for mod in self.modules:\n",
    "            if mod in database:\n",
    "                seq[str(i)+\"_\"+mod] = database[mod] #grab the sequences we need from the original dictionary\n",
    "                i+=1\n",
    "        return seq\n",
    "\n",
    "    def find_junctions(self): \n",
    "        \"\"\"This is a junction generating function\n",
    "        \n",
    "        Generate the junctions between two sequences, and all possible\n",
    "        codon combinations for each junction\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            a dictionary where keys are junction names and \n",
    "            values are their possible codon combinations\n",
    "        \"\"\"\n",
    "        \n",
    "        def reverse_translate(aa_seq, former_dna, latter_dna, num_base_f, num_base_l, enzyme_site):\n",
    "            \"\"\"This is a reverse translation function\n",
    "\n",
    "            Reverse translate the protein sequence to\n",
    "            all possible DNA sequences\n",
    "\n",
    "            Args:\n",
    "                aa_seq(str): a string of amino acid sequence\n",
    "\n",
    "            Returns:\n",
    "                a list containing all possible codon combinations\n",
    "            \"\"\"\n",
    "            enzyme_name_list = []\n",
    "            site_length_list = []\n",
    "            overhang_left_list = []\n",
    "            overhang_right_list = []\n",
    "            for i in enzyme_site:\n",
    "                enzyme_name_list.append(i)\n",
    "                site_length_list.append(len(enzyme_site[i]))\n",
    "                overhang_left_list.append(former_dna[::-1][num_base_f*3:num_base_f*3+len(enzyme_site[i])-1][::-1])\n",
    "                overhang_right_list.append(latter_dna[num_base_l*3:num_base_l*3+len(enzyme_site[i])-1])\n",
    "                        \n",
    "            seq_codons = []\n",
    "            for x in aa_seq:\n",
    "                seq_codons.append(self.DNA_codons[x]) #grab all codons for each amino acid\n",
    "            result = []\n",
    "            for r in product(*seq_codons):\n",
    "                r_joined = \"\".join(r)\n",
    "                enzyme_exclude_count = 0\n",
    "                for i in range(len(enzyme_site)):\n",
    "                    site_length = site_length_list[i]\n",
    "                    overhang_left = overhang_left_list[i]\n",
    "                    overhang_right = overhang_right_list[i]\n",
    "                    if (enzyme_site[enzyme_name_list[i]] not in overhang_left+r_joined+overhang_right):\n",
    "                        enzyme_exclude_count += 1\n",
    "                if enzyme_exclude_count == len(enzyme_site):\n",
    "                    result.append(r_joined) #generate all possible combinations of these codons\n",
    "            return result #list\n",
    "        \n",
    "        enzyme_site = self.enzyme_site\n",
    "        num_base_f = int(self.junc_aa_num.split('+')[0])\n",
    "        num_base_l = int(self.junc_aa_num.split('+')[1])\n",
    "        protein_seq = self.find_sequence(self.module_protein)\n",
    "        dna_seq = self.find_sequence(self.module_dna)\n",
    "        junc_seq = {}\n",
    "        names = tuple(protein_seq.keys())\n",
    "        length = len(protein_seq.keys())\n",
    "        for i in range(length-1):\n",
    "            former_seq = names[i]\n",
    "            latter_seq = names[i+1]\n",
    "            junc_aa = protein_seq[former_seq][::-1][0:num_base_f][::-1] + protein_seq[latter_seq][0:num_base_l]\n",
    "            junc_seq[str(i+1)+\"_\"+junc_aa] = reverse_translate(junc_aa, dna_seq[names[i]], dna_seq[names[i+1]], num_base_f, num_base_l, enzyme_site) \n",
    "            # find all DNA sequences for each junction\n",
    "        return junc_seq #dict\n",
    "    \n",
    "    def self_score(self, overhang_set):\n",
    "        \"\"\"This is a self scoring function\n",
    "\n",
    "        Based on the combination frequency to score the quality\n",
    "        of each overhang\n",
    "\n",
    "        Args:\n",
    "            overhang_set(list): a list of overhangs; example is [1_AAAA, 2_TTTT]\n",
    "\n",
    "        Returns:\n",
    "            a list containing the score of each overhang\n",
    "        \"\"\"\n",
    "        score = []\n",
    "        for o in overhang_set:\n",
    "            for m in self.scores_self:\n",
    "                if o[-4:] == m:\n",
    "                    s = self.scores_self[m]\n",
    "                    score.append(s/self.max_self_score)\n",
    "        return score #list, return the corresponding scores\n",
    "    \n",
    "    def overall_score(self, overhang_set, mmr=False):\n",
    "        \"\"\"This is a overall scoring function\n",
    "        \n",
    "        Based on the combination frequency to score the quality\n",
    "        of the set of overhangs\n",
    "        \n",
    "        Args:\n",
    "            overhang_set(list): a list of the overhangs (no less than 2); example is [1_AAAA, 2_TTTT]\n",
    "            mmr(bool): a boof about the value returned\n",
    "            \n",
    "        Returns:\n",
    "            (mmr=True)the mismatch rates of each overhang\n",
    "            (mmr=False)the score which sums up all the scores between each overhang\n",
    "        \"\"\" \n",
    "                        \n",
    "        def reverse_complementary(seq):\n",
    "            \"\"\"This is a reverse and complementary sequence generating function\n",
    "\n",
    "            Based on the principle of complementary base pairing, generate \n",
    "            the complementary sequence of the given DNA sequence\n",
    "\n",
    "            Args:\n",
    "                seq(str): a string of DNA sequence\n",
    "\n",
    "            Returns:\n",
    "                a string of the complementary sequence or the error message\n",
    "            \"\"\"\n",
    "            base_paring = {\"A\":\"T\",\"T\":\"A\",\"C\":\"G\",\"G\":\"C\"}\n",
    "            result = \"\"\n",
    "            for n in seq:\n",
    "                for b in base_paring:\n",
    "                    if n==b:\n",
    "                        result += base_paring[b]\n",
    "            return result[::-1]\n",
    "        \n",
    "        maxmax = self.max_self_score**2\n",
    "        scores = self.scores_overall\n",
    "        score = 0\n",
    "        overhang_from_set = list(combinations(overhang_set, 2)) #determine one pair of overhangs in the set\n",
    "        cbn_score = {} #record the score of each combination\n",
    "        for os in overhang_from_set:\n",
    "            if os[0][-4:] == os[1][-4:]:\n",
    "                score = maxmax\n",
    "                break\n",
    "            os1 = (os[0][-4:],reverse_complementary(os[1][-4:]))\n",
    "            os2 = (reverse_complementary(os[0][-4:]),os[1][-4:])\n",
    "            score += scores[os1]+scores[os2]\n",
    "            cbn_score[os] = scores[os1]+scores[os2]\n",
    "            #if two pairs are same, or not fully complementary,\n",
    "            #they are the possible mismatiched overhangs and the score should be added\n",
    "        if mmr == True:\n",
    "            overhang_mmr = []\n",
    "            for o in overhang_set:\n",
    "                o_score = 0\n",
    "                for c in cbn_score:\n",
    "                    if o in c:\n",
    "                        o_score += cbn_score[c]\n",
    "                mismatch_rate = o_score/self.self_score([o])[0]\n",
    "                overhang_mmr.append(mismatch_rate)\n",
    "            return overhang_mmr\n",
    "                       \n",
    "        # to prevent there is any overhang which has high mismatch score\n",
    "        return round(score*2/(len(overhang_set)**2-len(overhang_set)), 4)\n",
    "    \n",
    "    def find_position(self, overhang_set, Junctions):\n",
    "        \"\"\"This is a overhang postition searching function\n",
    "        \n",
    "        Find the all postions of the first base of the overhangs\n",
    "        in their own junctions\n",
    "        \n",
    "        Args:\n",
    "            overhang_set(list):a list of the overhang(s)\n",
    "            Junctions(dict):a dictionary contains junction sequences and their DNA sequences\n",
    "            \n",
    "        Returns:\n",
    "            a dictionary where the keys are overhangs and \n",
    "            values are their positions\n",
    "        \"\"\"\n",
    "        if overhang_set == []:\n",
    "            overhang_position = {'0_0':[0]}\n",
    "        else:\n",
    "            emptyp = []\n",
    "            for i in range(len(overhang_set)):\n",
    "                emptyp.append([]) #generate same length list, to store the position number\n",
    "            overhang_position = dict(zip(overhang_set,emptyp)) #combine the overhang list and empty position list together\n",
    "            for junc_name in Junctions:\n",
    "                junc_num = tuple(Junctions.keys()).index(junc_name)\n",
    "                overhang = overhang_set[junc_num]\n",
    "                for s in range(len(Junctions[junc_name])):\n",
    "                    if overhang[-4:] in Junctions[junc_name][s]:\n",
    "                        position = []\n",
    "                        for p in finditer(overhang[-4:], Junctions[junc_name][s]):\n",
    "                            position.append(p.start())\n",
    "                        if position not in overhang_position[overhang]:\n",
    "                            overhang_position[overhang].append(position)\n",
    "        return overhang_position\n",
    "    \n",
    "    def most_least_common_codons(self):\n",
    "        \"\"\"This is a most commonly used codons generating function\n",
    "        \n",
    "        Based on Ecoli codon usage bias table, to generate the most commonly used codon for each amino acid\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "            \n",
    "        Returns:\n",
    "            a dictionary where keys are amino acids and values are the frequency of the most common one\n",
    "        \"\"\"\n",
    "        Ecoli_most_common_codons = {}\n",
    "        for aa in self.DNA_codons:\n",
    "            max_bias = 0\n",
    "            for codon in self.DNA_codons[aa]:\n",
    "                bias = self.Ecoli_codon_bias[codon]\n",
    "                if bias > max_bias:\n",
    "                    max_bias = bias\n",
    "            Ecoli_most_common_codons[aa] = max_bias\n",
    "        \n",
    "        Ecoli_least_common_codons = {}\n",
    "        for aa in self.DNA_codons:\n",
    "            min_bias = 1\n",
    "            for codon in self.DNA_codons[aa]:\n",
    "                bias = self.Ecoli_codon_bias[codon]\n",
    "                if bias < min_bias:\n",
    "                    min_bias = bias\n",
    "            Ecoli_least_common_codons[aa] = min_bias\n",
    "        return Ecoli_most_common_codons, Ecoli_least_common_codons\n",
    "    \n",
    "    def seq_bias(self, overhang_position, Junctions, Ecoli_most_common_codons, Ecoli_least_common_codons):\n",
    "        \"\"\"This is a function for searching the junction DNA sequence with the highest bias score \n",
    "        \n",
    "        Based on the overhangs and positions, find all possible DNA sequences in each junctions, \n",
    "        then return the one with highest bias score\n",
    "        \n",
    "        Args:\n",
    "            overhang_position(dict): a dictionary contains overhangs and their positions\n",
    "            Junctions(dict):a dictionary contains junction sequences and their DNA sequences\n",
    "            Ecoli_most_common_codons(dict): a dictionary containing amino acids and their mostly used codons\n",
    "            Ecoli_least_common_codons(dict): a dictionary containing amino acids and their least used codons\n",
    "        \n",
    "        Returns:\n",
    "            a dictionary where keys are junction DNA sequences and values are their codon bias percentage\n",
    "        \"\"\"\n",
    "        \n",
    "        def bias_score(seq, junction, Ecoli_most_common_codons, Ecoli_least_common_codons):\n",
    "            \"\"\"This is a codon bias scoring function\n",
    "            \n",
    "            Based on the E.coli codon usage bias, add up the frequency of all codons in the sequnece\n",
    "            \n",
    "            Args:\n",
    "                seq(str): a string of DNA sequence translated from amino acid sequence\n",
    "                junction(str): a string of junction in amino acid sequence\n",
    "                Ecoli_most_common_codons(dict): a dictionary containing amino acids and their mostly used codons\n",
    "                Ecoli_least_common_codons(dict): a dictionary containing amino acids and their least used codons\n",
    "                \n",
    "            Returns:\n",
    "                a float number, the ratio of the sum of bias scores to the sum of max scores\n",
    "            \"\"\"\n",
    "            if len(seq)%3 != 0:\n",
    "                return \"Not divisible by 3\"\n",
    "            else:\n",
    "                min_score = 0\n",
    "                for a in junction:\n",
    "                    min_score += Ecoli_least_common_codons[a]\n",
    "                max_score = 0\n",
    "                for a in junction:\n",
    "                    max_score += Ecoli_most_common_codons[a]\n",
    "                score = 0\n",
    "                for i in range(0,len(seq),3):\n",
    "                    score += self.Ecoli_codon_bias[seq[i:i+3]]\n",
    "                return round((score-min_score)/(max_score-min_score), 2)\n",
    "        \n",
    "        if (overhang_position == {'0_0':[0]}) or ([] in overhang_position.values()):\n",
    "            best_oseq = {'0_0':0}\n",
    "        else:\n",
    "            best_oseq = {}\n",
    "            sum_score = 0\n",
    "            for junc_name in Junctions:\n",
    "                oseq_score = {}\n",
    "                num = tuple(Junctions.keys()).index(junc_name)\n",
    "                overhang = tuple(overhang_position.keys())[int(num)]\n",
    "                position = overhang_position[overhang]\n",
    "                for seq in Junctions[junc_name]:\n",
    "                    if overhang[-4:] in seq:\n",
    "                        if [p.start() for p in finditer(overhang[-4:],seq)] in position:\n",
    "                            score = bias_score(seq, junc_name.split(\"_\")[1], Ecoli_most_common_codons, Ecoli_least_common_codons)\n",
    "                            oseq_score[seq] = score\n",
    "                oseq_score_sorted = sorted(oseq_score.items(), key=lambda x:x[1], reverse=True)\n",
    "                best_oseq[str(num+1)+\"_\"+oseq_score_sorted[0][0]] = oseq_score_sorted[0][1]\n",
    "        return best_oseq\n",
    "\n",
    "    def find_primer(self, best_overhang_position, max_seq_bias):\n",
    "        \"\"\"This is a primer generation function\n",
    "        \n",
    "        Based on the DNA files, restriction file and the overhangs, to generate upstream and \n",
    "        downstream primers for each sequence\n",
    "        \n",
    "        Args:\n",
    "            best_overhang_position(dict): a dictionary of overhangs and their positions\n",
    "            max_seq_bias(dict): a dictionary of overhang sequences and their codon usage scores\n",
    "            \n",
    "        Returns:\n",
    "            a dictionary of primer names and the primers\n",
    "        \"\"\"\n",
    "        def Dot_Seq(DNA_sequence, junc_sequence, former_len, offset, direction):\n",
    "            junc_sequence = junc_sequence.split('_')[1]\n",
    "            if direction == 'front':\n",
    "                dot_seq = ''\n",
    "                if DNA_sequence[offset+13] in ['C','G']:\n",
    "                    dot_seq = DNA_sequence[offset:offset+14]\n",
    "                if DNA_sequence[offset+14] in ['C','G']:\n",
    "                    dot_seq = DNA_sequence[offset:offset+15]\n",
    "                if DNA_sequence[offset+15] in ['C','G']:\n",
    "                    dot_seq = DNA_sequence[offset:offset+16]\n",
    "                if dot_seq == '':\n",
    "                    dot_seq = DNA_sequence[offset:offset+15]+'C'        \n",
    "            if direction == 'back':\n",
    "                dot_seq = ''\n",
    "                if DNA_sequence[offset-14] in ['C','G']:\n",
    "                    dot_seq = DNA_sequence[::-1][former_len:14-offset][::-1]+junc_sequence[:(former_len+offset)]\n",
    "                if DNA_sequence[offset-15] in ['C','G']:\n",
    "                    dot_seq = DNA_sequence[::-1][former_len:15-offset][::-1]+junc_sequence[:(former_len+offset)]\n",
    "                if DNA_sequence[offset-16] in ['C','G']:\n",
    "                    dot_seq = DNA_sequence[::-1][former_len:16-offset][::-1]+junc_sequence[:(former_len+offset)]\n",
    "                if dot_seq == '':\n",
    "                    dot_seq = 'C'+DNA_sequence[::-1][former_len:15-offset][::-1]+junc_sequence[:(former_len+offset)]\n",
    "            return dot_seq\n",
    "        \n",
    "        if (best_overhang_position == {'0_0':[0]}) or (max_seq_bias == {'0_0':0}):\n",
    "            Primer_list = {'0_0':0}\n",
    "        else:\n",
    "            Primer_list = {}\n",
    "            dna_seq = self.find_sequence(self.module_dna)\n",
    "            for i in dna_seq:\n",
    "                if int(i.split('_')[0]) == 1:\n",
    "                    position = list(best_overhang_position.values())[int(i.split('_')[0])-1][0]\n",
    "                    former_len = list(map(int, self.junc_aa_num.split('+')))[0]*3\n",
    "                    Primer_list[i+'_US'] = 'TCAGCATATG' + Dot_Seq(dna_seq[list(dna_seq.keys())[int(i.split('_')[0])-1]], list(max_seq_bias.keys())[int(i.split('_')[0])-1], former_len, 0, 'front')       \n",
    "                    if position < former_len-3:\n",
    "                        extra_seq = ''\n",
    "                        offset = -(former_len-position-4)\n",
    "                        dot_seq = Dot_Seq(dna_seq[list(dna_seq.keys())[int(i.split('_')[0])-1]], list(max_seq_bias.keys())[int(i.split('_')[0])-1], former_len, offset, 'back')\n",
    "                    if position >= former_len-3:\n",
    "                        extra_seq = list(max_seq_bias.keys())[int(i.split('_')[0])-1].split('_')[1][former_len:position+4]\n",
    "                        dot_seq = Dot_Seq(dna_seq[list(dna_seq.keys())[int(i.split('_')[0])-1]], list(max_seq_bias.keys())[int(i.split('_')[0])-1], former_len, 0, 'back')\n",
    "                    Primer_list[i+'_DS'] = dot_seq + extra_seq + 'TGAGACCCTCGAGTAA'\n",
    "                elif int(i.split('_')[0]) == len(dna_seq):\n",
    "                    former_len = list(map(int, self.junc_aa_num.split('+')))[0]*3\n",
    "                    Primer_list[i+'_US'] = 'TCAGCATATGAGGTCTCC' + Dot_Seq(dna_seq[list(dna_seq.keys())[int(i.split('_')[0])-1]], list(max_seq_bias.keys())[len(max_seq_bias)-1], 0, 0, 'front')\n",
    "                    Primer_list[i+'_DS'] = Dot_Seq(dna_seq[list(dna_seq.keys())[int(i.split('_')[0])-1]], list(max_seq_bias.keys())[len(max_seq_bias)-1], 0, 0, 'back') + 'GGTTGGCTCGAGATAG'\n",
    "                    # list(max_seq_bias.keys())[len(max_seq_bias)-1] is useless actually, just to keep the input format.\n",
    "                else:\n",
    "                    position = list(best_overhang_position.values())[int(i.split('_')[0])-1][0]\n",
    "                    former_len = list(map(int, self.junc_aa_num.split('+')))[0]*3\n",
    "                    Primer_list[i+'_US'] = 'TCAGCATATGAGGTCTCC' + Dot_Seq(dna_seq[list(dna_seq.keys())[int(i.split('_')[0])-1]], list(max_seq_bias.keys())[int(i.split('_')[0])-1], former_len, 0, 'front')\n",
    "                    if position < former_len-3:\n",
    "                        extra_seq = ''\n",
    "                        offset = -(former_len-position-4)\n",
    "                        dot_seq = Dot_Seq(dna_seq[list(dna_seq.keys())[int(i.split('_')[0])-1]], list(max_seq_bias.keys())[int(i.split('_')[0])-1], former_len, offset, 'back')\n",
    "                    if position >= former_len-3:\n",
    "                        extra_seq = list(max_seq_bias.keys())[int(i.split('_')[0])-1].split('_')[1][former_len:position+4]\n",
    "                        dot_seq = Dot_Seq(dna_seq[list(dna_seq.keys())[int(i.split('_')[0])-1]], list(max_seq_bias.keys())[int(i.split('_')[0])-1], former_len, 0, 'back')\n",
    "                    Primer_list[i+'_DS'] = dot_seq + extra_seq + 'TGAGACCCTCGAGTAA'\n",
    "        return Primer_list       \n",
    "\n",
    "class Operators:\n",
    "    \"\"\"This is a class for genetic algorithm\n",
    "\n",
    "    Operators class is the set of arguments and functions of genetic algorithm. \n",
    "    It contains general attributes of init_num, mutation_rate, crossover_rate, \n",
    "    pre, and ovset; and functions of start, select, mutate, and crossover.\n",
    "\n",
    "    Attributes:\n",
    "        init_num: an int number of initial individuals\n",
    "        mutation_rate: a float number of mutation rate\n",
    "        crossover_rate: a float number of crossover rate\n",
    "        pre: a object of a class; \n",
    "        ovset: a string of overhangs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, init_num, mutation_rate, crossover_rate, pre, ovset):\n",
    "\n",
    "        \"\"\"Initialize Operators class\n",
    "        \n",
    "        details\n",
    "        \n",
    "        Args:\n",
    "            init_num(int): initial number of individuals, must be divisible by 10; example is 10\n",
    "            mutation_rate(float): mutation rate; example is 0\n",
    "            crossover_rate(float): crossover rate; example is 0\n",
    "            pre(object): object name; example is the objcet of class Tools\n",
    "            ovset(str): overhangs determined; example is '1_AAAA\\n2_AAAT\\n' \n",
    "        \"\"\"\n",
    "        self.init_num = init_num\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.pre = pre\n",
    "        self.ovset = ovset\n",
    "    \n",
    "    def start(self, Junctions, init_num, ovset):\n",
    "        \"\"\"This is a initial individuals generating function\n",
    "        \n",
    "        Generate a certain number(init_num) of initial individuals randomly.\n",
    "        Each individual contains an overhang set and its overall score.\n",
    "        \n",
    "        Args:\n",
    "            Junctions(dict): a dictionary of the junction names and their sequences\n",
    "            init_num(number): an int number to determine the number of initial individuals\n",
    "            ovset(str): a string of overhangs determined\n",
    "            \n",
    "        Returns:\n",
    "            a dictionary where the keys are overhang sets and \n",
    "            values are their overall score\n",
    "        \"\"\"\n",
    "        individuals = {}\n",
    "        for num in range(init_num):\n",
    "            overhang_set = []\n",
    "            for junc_name in Junctions:\n",
    "                junc_num = tuple(Junctions.keys()).index(junc_name)\n",
    "                p = randint(0 , self.pre.junc_aa_sum*3-4)\n",
    "                seq = sample(list(Junctions[junc_name]),1)\n",
    "                overhang = seq[0][p:p+4]\n",
    "                overhang_set.append(str(junc_num+1)+\"_\"+overhang)\n",
    "            for i in ovset.split('\\n'):\n",
    "                if i.split('_')[1] != '':\n",
    "                    overhang_set[int(i.split('_')[0])-1] = i\n",
    "            ov_score = self.pre.overall_score(overhang_set)\n",
    "            individuals[\" \".join(overhang_set)] = ov_score\n",
    "        return individuals  \n",
    "        \n",
    "    def select(self, indiv_set, self_score_lower_limit): #what to do if most or all individuals contain the <500 overhang?\n",
    "        \"\"\"This is a selection function\n",
    "        \n",
    "        Filter out the individuals which contains the overhang below a certain self score; then filter\n",
    "        the top half individuals based on overall score\n",
    "        \n",
    "        Args:\n",
    "            indiv_set(dict): a dictionary where keys are overhang sets and values are their overall scores\n",
    "            self_score_lower_limit(int): a number that the lower limit of self score is\n",
    "            \n",
    "        Returns:\n",
    "            a dictionary where keys are overhang sets and values are their overall scores\n",
    "        \"\"\"\n",
    "        num = len(indiv_set)*0.5\n",
    "        indiv_set_HQ = dict(tuple(indiv_set.items()))\n",
    "        for i in indiv_set:\n",
    "            o = i.split(\" \")\n",
    "            scores = self.pre.self_score(o)\n",
    "            for s in scores:\n",
    "                if s < self_score_lower_limit:\n",
    "                    del indiv_set_HQ[i]\n",
    "                    break\n",
    "        indiv_set_sorted = sorted(indiv_set_HQ.items(), key=lambda x:x[1], reverse=False)\n",
    "        tops = dict(indiv_set_sorted[0:int(num)])\n",
    "        return tops\n",
    "        \n",
    "    def mutate(self, indiv_set, Junctions):\n",
    "        \"\"\"This is a mutation function\n",
    "        \n",
    "        Each overhang in each individuals has a certain chance to be replaced by a random\n",
    "        overhang from the same junction pool\n",
    "        \n",
    "        Args:\n",
    "            indiv_set(list): a list of individuals\n",
    "            Junctions(dict): a dictionary containing all DNA sequences in each junction\n",
    "        \n",
    "        Returns:\n",
    "            a list of the mutated individuals\n",
    "        \"\"\"\n",
    "        for n in range(len(indiv_set)):\n",
    "            overhang_set = indiv_set[n].split()\n",
    "            for i in range(len(overhang_set)):\n",
    "                x = uniform(0,1)\n",
    "                if x < self.mutation_rate:\n",
    "                    junc_name = tuple(Junctions.keys())[i]\n",
    "                    p = randint(0 , self.pre.junc_aa_sum*3-4)\n",
    "                    seq = sample(list(Junctions[junc_name]),1)\n",
    "                    overhang = seq[0][p:p+4]\n",
    "                    overhang_set[i] = str(i+1)+\"_\"+overhang\n",
    "            indiv_set[n] = \" \".join(overhang_set)\n",
    "        return indiv_set\n",
    "\n",
    "    def crossover(self, indiv_set):\n",
    "        \"\"\"This is a crossover function\n",
    "        \n",
    "        Grouping all individuals in random pairs. for each junction, the paired overhang sets\n",
    "        has a certain chance to exchange their overhangs.\n",
    "        \n",
    "        Args:\n",
    "            indiv_set(list): a list of individuals\n",
    "        \n",
    "        Returns:\n",
    "            a list of crossovered individuals\n",
    "        \"\"\"\n",
    "        if indiv_set == []:\n",
    "            return indiv_set\n",
    "        else:\n",
    "            indiv_set_listed = []\n",
    "            for i in indiv_set:\n",
    "                indiv_set_listed.append(i.split())\n",
    "            junc_num = len(indiv_set[0].split())\n",
    "\n",
    "            crossed_set = []\n",
    "            cross_group = []\n",
    "            for g in range(int(len(indiv_set)/2)):\n",
    "                group_num = sample(range(len(indiv_set_listed)), 2)\n",
    "                group_num = sorted(group_num,reverse=False)\n",
    "                group = []\n",
    "                for a in list(group_num):\n",
    "                    group.append(indiv_set_listed[a])\n",
    "                cross_group.append(group)\n",
    "                indiv_set_listed_dep = []\n",
    "                for y in range(len(indiv_set_listed)):\n",
    "                    if y not in group_num:\n",
    "                        indiv_set_listed_dep.append(indiv_set_listed[y])\n",
    "                indiv_set_listed = indiv_set_listed_dep\n",
    "            for n in range(len(cross_group)):\n",
    "                grps = cross_group[n]\n",
    "                for j in range(junc_num):\n",
    "                    x = uniform(0,1)\n",
    "                    if x < self.crossover_rate:\n",
    "                        dep = grps[0][j]\n",
    "                        grps[0][j] = grps[1][j]\n",
    "                        grps[1][j] = dep\n",
    "                crossed_set.append(\" \".join(grps[0]))\n",
    "                crossed_set.append(\" \".join(grps[1]))\n",
    "            return crossed_set\n",
    "\n",
    "# Monte carlo\n",
    "def Montecarlo(files, DNA_files, Restriction_file, modules, times_uppser_limit, times_lower_limit, self_score_lower_limit,\n",
    "               aa_num, score_table, loadingwin, loadingbar, Ecoli_codon_bias, ovset):\n",
    "    \n",
    "    time_start = perf_counter() #timing\n",
    "    monte_pre = Tools(modules,files,aa_num,score_table, DNA_files, Restriction_file) #tools object\n",
    "    Junctions = monte_pre.find_junctions() #generate all possible sequences in the jucntions\n",
    "    Ecoli_most_common_codons, Ecoli_least_common_codons = monte_pre.most_least_common_codons()\n",
    "\n",
    "    min_ov_score = 9999\n",
    "    times = 0\n",
    "    max_seq_bias = {\"\":0}\n",
    "    best_overhang_position = []\n",
    "\n",
    "    while (min_ov_score > 0) or (sum(max_seq_bias.values())/len(Junctions) < Ecoli_codon_bias) or (times < times_lower_limit):\n",
    "        #stop condition is that overall score is 0, and below codon bias limit;\n",
    "        overhang_set = []\n",
    "        for junc_name in Junctions:\n",
    "            junc_num = tuple(Junctions.keys()).index(junc_name)\n",
    "            overhang_score = self_score_lower_limit\n",
    "            while overhang_score <= self_score_lower_limit:\n",
    "                p = randint(0 , monte_pre.junc_aa_sum*3-4)\n",
    "                seq = sample(list(Junctions[junc_name]),1)\n",
    "                overhang = seq[0][p:p+4]\n",
    "                overhang_score = monte_pre.self_score([overhang])[0]\n",
    "            overhang_set.append(str(junc_num+1)+\"_\"+overhang)\n",
    "            # randomly generate the overhang whose self score is above self_score_lower_limit\n",
    "        for i in ovset.split('\\n'):\n",
    "            if i.split('_')[1] != '':\n",
    "                overhang_set[int(i.split('_')[0])-1] = i\n",
    "                # replaced by the overhangs determined in some positions\n",
    "        ov_score = monte_pre.overall_score(overhang_set) #calculate overall score\n",
    "        if ov_score < min_ov_score:\n",
    "            overhang_position = monte_pre.find_position(overhang_set, Junctions)\n",
    "            overhang_seq_bias= monte_pre.seq_bias(overhang_position, Junctions, Ecoli_most_common_codons, Ecoli_least_common_codons)\n",
    "            min_ov_score = ov_score\n",
    "            max_seq_bias = overhang_seq_bias\n",
    "            best_overhang_position = overhang_position\n",
    "        if Ecoli_codon_bias == 1:\n",
    "            if ov_score == min_ov_score:\n",
    "                overhang_position = monte_pre.find_position(overhang_set, Junctions)\n",
    "                overhang_seq_bias= monte_pre.seq_bias(overhang_position, Junctions, Ecoli_most_common_codons, Ecoli_least_common_codons)\n",
    "                if sum(max_seq_bias.values()) <= sum(overhang_seq_bias.values()):\n",
    "                    min_ov_score = ov_score\n",
    "                    max_seq_bias = overhang_seq_bias\n",
    "                    best_overhang_position = overhang_position\n",
    "        # record the overhang set with minimal overall score and highest bias score\n",
    "        loadingbar.step(1)\n",
    "        loadingwin.update()\n",
    "        times += 1\n",
    "        if times >= times_uppser_limit:\n",
    "            break # if exceed max cycle times, then stop\n",
    "    for o,s in zip(best_overhang_position, max_seq_bias):\n",
    "        best_overhang_position[o] = [p.start() for p in finditer(o[-4:], s.split(\"_\")[1])]\n",
    "    time_end = perf_counter() #timing\n",
    "\n",
    "    OFF_ON=[\"OFF\",\"ON\"]\n",
    "    aa_num_former = list(map(int, aa_num.split('+')))[0]\n",
    "    aa_sum = sum(list(map(int, aa_num.split('+'))))\n",
    "    juncs = \"  \".join(Junctions.keys())\n",
    "    filetime = datetime.now().strftime(\"%c\").replace(\":\",\"-\").replace(\" \",\"_\")\n",
    "    primer_list = monte_pre.find_primer(best_overhang_position, max_seq_bias)\n",
    "    overhang_mmr = monte_pre.overall_score(list(best_overhang_position.keys()), mmr=True)\n",
    "    with open(f\"Monte Carlo Running Report - {filetime}.txt\", \"w\") as f:\n",
    "        f.write(f\"This is the result from Monte Carlo algorithm\\n\\n\")\n",
    "        f.write(f\"Mostly used codons: {OFF_ON[Ecoli_codon_bias]}\\nResidue number: {aa_num}\\nLigation time: {score_table.split('_')[0]}\\nTempreture: {score_table.split('_')[1]}\\n\")\n",
    "        f.write(f\"Overhang quality limit: {self_score_lower_limit}\\nMaximum cycles: {times_uppser_limit}\\nMinimum cycles: {times_lower_limit}\\n\\n\")\n",
    "        f.write(f\"Protein files:\\n{files}\\n\\nDNA files:\\n{DNA_files}\\n\\n\")\n",
    "        f.write(f\"Restriction sites avoided: \")\n",
    "        for i in monte_pre.enzyme_site:\n",
    "            f.write(f\"{i}, \")\n",
    "        f.write(f\"\\n{Restriction_file}\\n\\n\")\n",
    "        f.write(f\"Modules:\\n\")\n",
    "        for i in modules:\n",
    "            f.write(f\"{i}  \")\n",
    "        f.write(f\"\\n\\nJunctions:\\n{juncs}\\n\\n\")\n",
    "        f.write(f\"totally {times} cycles\\nRunning time: {time_end-time_start} seconds\\n\\n\")\n",
    "        f.write(f\"the overall mismatch score is {min_ov_score}\\n\")\n",
    "        f.write(f\"No.  Overhang  former3'end(1-{aa_num_former*3})  latter5'end({aa_num_former*3+1}-{aa_sum*3})  Position(1-{aa_sum*3})  Codon_usage_score  Mismatch_rate\\n\")\n",
    "        for a,b,c in zip(best_overhang_position, max_seq_bias, overhang_mmr):\n",
    "            col_No = int(a.split(\"_\")[0])\n",
    "            col_Overhang = a.split(\"_\")[1]\n",
    "            col_DNA_Sequence = b.split(\"_\")[1]\n",
    "            col_Position = \", \".join(list(map(lambda x:str(x+1),best_overhang_position[a])))\n",
    "            col_Codon_bias_score = max_seq_bias[b]\n",
    "            f.write(f\"{col_No}    {col_Overhang}    {col_DNA_Sequence[0:aa_num_former*3]}    {col_DNA_Sequence[aa_num_former*3:]}    {col_Position}    {col_Codon_bias_score}    {c}\\n\")\n",
    "        f.write(f\"\\nPrimer details:(_US means upstream; _DS means downstream)\\n\")\n",
    "        for i in primer_list:\n",
    "            f.write(f\"{i}: {primer_list[i]}\\n\")   \n",
    "    loadingbar['value'] = times_uppser_limit+1\n",
    "            \n",
    "# Greedy algorithm\n",
    "def Greedy(files, DNA_files, Restriction_file, modules, self_score_lower_limit, aa_num, score_table, \n",
    "           loadingwin, loadingbar, Ecoli_codon_bias, ovset):\n",
    "    \n",
    "    time_start = perf_counter() # timing\n",
    "    aa_sum = sum(list(map(int, aa_num.split('+'))))\n",
    "    greedy_pre = Tools(modules,files,aa_num,score_table, DNA_files, Restriction_file) # tools object\n",
    "    Junctions = greedy_pre.find_junctions()# generate all sequences in the Junctions\n",
    "    Ecoli_most_common_codons, Ecoli_least_common_codons = greedy_pre.most_least_common_codons()\n",
    "    overhang_set = []\n",
    "\n",
    "    for junc_name in Junctions:\n",
    "        junc_num = tuple(Junctions.keys()).index(junc_name)\n",
    "        indiv_scores = {}\n",
    "        for s in range(len(Junctions[junc_name])):\n",
    "            for p in range(0,aa_sum*3-4):\n",
    "                overhang = Junctions[junc_name][s][p:p+4]\n",
    "                score = greedy_pre.self_score([overhang])[0]\n",
    "                if overhang not in indiv_scores:\n",
    "                    if score > self_score_lower_limit:\n",
    "                        indiv_scores[overhang] = score\n",
    "        indiv_scores = dict(sorted(indiv_scores.items(), key=lambda x:x[1], reverse=True))\n",
    "        #for each junction, generate and sort all possible overhangs and their self score\n",
    "        if len(overhang_set) == 0:\n",
    "            if ovset.split('\\n')[0].split('_')[1] != '':\n",
    "                overhang_set.append(ovset.split('\\n')[0])\n",
    "            else:\n",
    "                highest_bias = 0\n",
    "                highest_bias_position = 0\n",
    "                bias = 0\n",
    "                position = 0\n",
    "                overhang = tuple(indiv_scores.keys())[position] #if codon bias=0, then output the first one; if 1, then go into loop.\n",
    "                if Ecoli_codon_bias == 1:\n",
    "                    while bias < Ecoli_codon_bias:\n",
    "                        if position >= len(indiv_scores):\n",
    "                            overhang = tuple(indiv_scores.keys())[highest_bias_position]\n",
    "                            break\n",
    "                        overhang = tuple(indiv_scores.keys())[position]\n",
    "                        junc_name = tuple(Junctions.keys())[len(overhang_set)]\n",
    "                        junc_seq = tuple(Junctions.values())[len(overhang_set)]\n",
    "                        overhang_p = greedy_pre.find_position([overhang], dict(zip([junc_name], [junc_seq])))\n",
    "                        bias = tuple(greedy_pre.seq_bias(overhang_p, dict(zip([junc_name], [junc_seq])), Ecoli_most_common_codons, Ecoli_least_common_codons).values())[0]\n",
    "                        if bias > highest_bias:\n",
    "                            highest_bias = bias\n",
    "                            highest_bias_position = position\n",
    "                        position += 1\n",
    "                overhang_set.append(\"1_\"+overhang)\n",
    "        # the first one will be recorded directly, if attain the criterions\n",
    "        else:\n",
    "            if ovset.split('\\n')[junc_num].split('_')[1] != '':\n",
    "                overhang_set.append(ovset.split('\\n')[junc_num])\n",
    "            else:\n",
    "                ov_score = 1\n",
    "                highest_bias = 0\n",
    "                lowest_ov = max(greedy_pre.scores_overall.values())\n",
    "                lowest_ov_position = 0\n",
    "                bias = 0\n",
    "                position = 0\n",
    "                while (ov_score > 0) or (bias < Ecoli_codon_bias):\n",
    "                    if position >= len(indiv_scores):\n",
    "                        overhang = tuple(indiv_scores.keys())[lowest_ov_position]\n",
    "                        break\n",
    "                    overhang = tuple(indiv_scores.keys())[position]\n",
    "                    ov_score = greedy_pre.overall_score(overhang_set+[overhang])\n",
    "                    junc_name = tuple(Junctions.keys())[len(overhang_set)]\n",
    "                    junc_seq = tuple(Junctions.values())[len(overhang_set)]\n",
    "                    overhang_p = greedy_pre.find_position([overhang], dict(zip([junc_name], [junc_seq])))\n",
    "                    bias = tuple(greedy_pre.seq_bias(overhang_p, dict(zip([junc_name], [junc_seq])), Ecoli_most_common_codons, Ecoli_least_common_codons).values())[0]\n",
    "                    if ov_score < lowest_ov:\n",
    "                        lowest_ov = ov_score\n",
    "                        lowest_ov_position = position\n",
    "                    if Ecoli_codon_bias == 1:\n",
    "                        if ov_score == lowest_ov:\n",
    "                            if bias > highest_bias:\n",
    "                                highest_bias = bias\n",
    "                                lowest_ov_position = position\n",
    "                    position += 1\n",
    "                overhang_set.append(str(junc_num+1)+\"_\"+overhang)\n",
    "        loadingbar.step(1)\n",
    "        loadingwin.update()\n",
    "        # the followings should be checked for overall score, if not attained, use the next one in this junction; if runs out, return \"None\"\n",
    "    ov_score = greedy_pre.overall_score(overhang_set)\n",
    "    if ov_score > 9999:\n",
    "        ov_score = 9999\n",
    "    overhang_position = greedy_pre.find_position(overhang_set, Junctions) #find the position\n",
    "    seq_bias = greedy_pre.seq_bias(overhang_position, Junctions, Ecoli_most_common_codons, Ecoli_least_common_codons) #find junction sequences\n",
    "    for o,s in zip(overhang_position, seq_bias):\n",
    "        overhang_position[o] = [p.start() for p in finditer(o[-4:], s.split(\"_\")[1])]\n",
    "    time_end = perf_counter()#timing\n",
    "\n",
    "    OFF_ON=[\"OFF\",\"ON\"]\n",
    "    aa_num_former = list(map(int, aa_num.split('+')))[0]\n",
    "    juncs = \"  \".join(Junctions.keys())\n",
    "    filetime = datetime.now().strftime(\"%c\").replace(\":\",\"-\").replace(\" \",\"_\")\n",
    "    primer_list = greedy_pre.find_primer(overhang_position, seq_bias)\n",
    "    overhang_mmr = greedy_pre.overall_score(list(overhang_position.keys()), mmr=True)\n",
    "    with open(f\"Greedy Running Report - {filetime}.txt\", \"w\") as f:        \n",
    "        f.write(f\"This is the result from Greedy algorithm\\n\\n\")\n",
    "        f.write(f\"Mostly used codons: {OFF_ON[Ecoli_codon_bias]}\\nResidue number: {aa_num}\\nLigation time: {score_table.split('_')[0]}\\nTempreture: {score_table.split('_')[1]}\\n\")\n",
    "        f.write(f\"Overhang quality limit: {self_score_lower_limit}\\n\\n\")\n",
    "        f.write(f\"Protein files:\\n{files}\\n\\nDNA files:\\n{DNA_files}\\n\\n\")\n",
    "        f.write(f\"Restriction sites avoided: \")\n",
    "        for i in greedy_pre.enzyme_site:\n",
    "            f.write(f\"{i}, \")\n",
    "        f.write(f\"\\n{Restriction_file}\\n\\n\")\n",
    "        f.write(f\"Modules:\\n\")\n",
    "        for i in modules:\n",
    "            f.write(f\"{i}  \")\n",
    "        f.write(f\"\\n\\nJunctions:\\n{juncs}\\n\\n\")\n",
    "        f.write(f\"Running time: {time_end-time_start} seconds\\n\\n\")        \n",
    "        f.write(f\"the overall mismatch score is {ov_score}\\n\")\n",
    "        f.write(f\"No.  Overhang  former3'end(1-{aa_num_former*3})  latter5'end({aa_num_former*3+1}-{aa_sum*3})  Position(1-{aa_sum*3})  Codon_usage_score  Mismatch_rate\\n\")\n",
    "        for a,b,c in zip(overhang_position, seq_bias, overhang_mmr):\n",
    "            col_No = int(a.split(\"_\")[0])\n",
    "            col_Overhang = a.split(\"_\")[1]\n",
    "            col_DNA_Sequence = b.split(\"_\")[1]\n",
    "            col_Position = \", \".join(list(map(lambda x:str(x+1),overhang_position[a])))\n",
    "            col_Codon_bias_score = seq_bias[b]\n",
    "            f.write(f\"{col_No}    {col_Overhang}    {col_DNA_Sequence[0:aa_num_former*3]}    {col_DNA_Sequence[aa_num_former*3:]}    {col_Position}    {col_Codon_bias_score}    {c}\\n\")\n",
    "        f.write(f\"\\nPrimer details:(_US means upstream; _DS means downstream)\\n\")\n",
    "        for i in primer_list:\n",
    "            f.write(f\"{i}: {primer_list[i]}\\n\") \n",
    "    loadingbar['value'] = len(modules)+1\n",
    "\n",
    "# Genetic algorithm\n",
    "def Genetic(files, DNA_files, Restriction_file, modules, init_num, mutation_rate, crossover_rate, max_generation_num, min_generation_num,\n",
    "            self_score_lower_limit, aa_num, score_table, loadingwin, loadingbar, Ecoli_codon_bias, ovset):\n",
    "\n",
    "    time_start = perf_counter() #timing\n",
    "    genetic_pre = Tools(modules,files,aa_num,score_table, DNA_files, Restriction_file) #tools object\n",
    "    operators = Operators(init_num=init_num, \n",
    "                          mutation_rate=mutation_rate, \n",
    "                          crossover_rate=crossover_rate,\n",
    "                          pre = genetic_pre,\n",
    "                          ovset = ovset) #operators object\n",
    "    Junctions = genetic_pre.find_junctions() #generate all possible DNA sequences in the junctions\n",
    "    Ecoli_most_common_codons, Ecoli_least_common_codons = genetic_pre.most_least_common_codons()\n",
    "    best_ov_score = 9999\n",
    "    best_average_bias = {\"\":0}\n",
    "    best_indiv = ''\n",
    "\n",
    "    initials = operators.start(Junctions, operators.init_num, ovset) #generate the initial individuals\n",
    "\n",
    "    G = 0\n",
    "    while (best_ov_score > 0) or (sum(best_average_bias.values())/len(Junctions) < Ecoli_codon_bias) or (G < min_generation_num):\n",
    "        indiv_set_selected = operators.select(initials, self_score_lower_limit) #filter the initials by overall score and self score\n",
    "        indiv_set_mutated = operators.mutate(list(indiv_set_selected.keys()), Junctions) #mutate them\n",
    "        indiv_set_crossed = operators.crossover(indiv_set_mutated) #crossover them\n",
    "        initials2 = {}\n",
    "        for overhang_set in indiv_set_crossed:\n",
    "            overhang_set = overhang_set.split()\n",
    "            ov_score = genetic_pre.overall_score(overhang_set)\n",
    "            initials2[\" \".join(overhang_set)] = ov_score\n",
    "        initials2 = dict(list(initials2.items())+list(indiv_set_selected.items())) #put the operated individuals and originals together\n",
    "        indiv_set_selected2 = operators.select(initials2, self_score_lower_limit) #filter the operateds and olds together\n",
    "        for indiv, score in indiv_set_selected2.items():\n",
    "            if score < best_ov_score:\n",
    "                overhang_position = genetic_pre.find_position(indiv.split(), Junctions)\n",
    "                bias = genetic_pre.seq_bias(overhang_position, Junctions, Ecoli_most_common_codons, Ecoli_least_common_codons)\n",
    "                best_ov_score = score\n",
    "                best_average_bias = bias\n",
    "                best_indiv = indiv  # record the best individual\n",
    "            if Ecoli_codon_bias == 1:\n",
    "                if score == best_ov_score:\n",
    "                    overhang_position = genetic_pre.find_position(indiv.split(), Junctions)\n",
    "                    bias = genetic_pre.seq_bias(overhang_position, Junctions, Ecoli_most_common_codons, Ecoli_least_common_codons)\n",
    "                    if sum(bias.values()) >= sum(best_average_bias.values()): \n",
    "                        best_ov_score = score\n",
    "                        best_average_bias = bias\n",
    "                        best_indiv = indiv  # record the best individual\n",
    "        new_indiv_set = operators.start(Junctions, (operators.init_num - len(indiv_set_selected2)), ovset) #add new random individuals to the initial number\n",
    "        indiv_set_next_generation = dict(list(indiv_set_selected2.items())+list(new_indiv_set.items())) # put old ones and new ones together\n",
    "        initials = {}\n",
    "        for overhang_set in indiv_set_next_generation:\n",
    "            overhang_set = overhang_set.split()\n",
    "            ov_score = genetic_pre.overall_score(overhang_set)\n",
    "            initials[\" \".join(overhang_set)] = ov_score\n",
    "        #regard the new generation as new initials\n",
    "        loadingbar.step(1)\n",
    "        loadingwin.update()\n",
    "        G += 1\n",
    "        if G >= max_generation_num:\n",
    "            break\n",
    "\n",
    "    overhang_position = genetic_pre.find_position(best_indiv.split(), Junctions)\n",
    "    seq_bias = genetic_pre.seq_bias(overhang_position, Junctions, Ecoli_most_common_codons, Ecoli_least_common_codons)\n",
    "    for o,s in zip(overhang_position, seq_bias):\n",
    "        overhang_position[o] = [p.start() for p in finditer(o[-4:], s.split(\"_\")[1])]\n",
    "    time_end = perf_counter() #timing\n",
    "\n",
    "    OFF_ON=[\"OFF\",\"ON\"]\n",
    "    aa_num_former = list(map(int, aa_num.split('+')))[0]\n",
    "    aa_sum = sum(list(map(int, aa_num.split('+'))))\n",
    "    juncs = \"  \".join(Junctions.keys())\n",
    "    filetime = datetime.now().strftime(\"%c\").replace(\":\",\"-\").replace(\" \",\"_\")\n",
    "    primer_list = genetic_pre.find_primer(overhang_position, seq_bias)\n",
    "    overhang_mmr = genetic_pre.overall_score(list(overhang_position.keys()), mmr=True)\n",
    "    with open(f\"Genetic Running Report - {filetime}.txt\", \"w\") as f:\n",
    "        f.write(f\"This is the result from Genetic algorithm\\n\\n\")\n",
    "        f.write(f\"Mostly used codons: {OFF_ON[Ecoli_codon_bias]}\\nResidue number: {aa_num}\\nLigation time: {score_table.split('_')[0]}\\nTempreture: {score_table.split('_')[1]}\\n\")\n",
    "        f.write(f\"Overhang quality limit: {self_score_lower_limit}\\nMaximum generations: {max_generation_num}\\nMinimum generations: {min_generation_num}\\nInitial number: {init_num}\\nMutation rate: {mutation_rate}\\nCrossover rate: {crossover_rate}\\n\\n\")\n",
    "        f.write(f\"Protein files:\\n{files}\\n\\nDNA files:\\n{DNA_files}\\n\\n\")\n",
    "        f.write(f\"Restriction sites avoided: \")\n",
    "        for i in genetic_pre.enzyme_site:\n",
    "            f.write(f\"{i}, \")\n",
    "        f.write(f\"\\n{Restriction_file}\\n\\n\")\n",
    "        f.write(f\"Modules:\\n\")\n",
    "        for i in modules:\n",
    "            f.write(f\"{i}  \")\n",
    "        f.write(f\"\\n\\nJunctions:\\n{juncs}\\n\\n\")\n",
    "        f.write(f\"totally {G} generations\\nRunning time: {time_end-time_start} seconds\\n\\n\")\n",
    "        f.write(f\"the overall mismatch score is {best_ov_score}\\n\")\n",
    "        f.write(f\"No.  Overhang  former3'end(1-{aa_num_former*3})  latter5'end({aa_num_former*3+1}-{aa_sum*3})  Position(1-{aa_sum*3-3})  Codon_usage_score  Mismatch_rate\\n\")\n",
    "        for a,b,c in zip(overhang_position, seq_bias, overhang_mmr):\n",
    "            col_No = int(a.split(\"_\")[0])\n",
    "            col_Overhang = a.split(\"_\")[1]\n",
    "            col_DNA_Sequence = b.split(\"_\")[1]\n",
    "            col_Position = \", \".join(list(map(lambda x:str(x+1),overhang_position[a])))\n",
    "            col_Codon_bias_score = seq_bias[b]\n",
    "            f.write(f\"{col_No}    {col_Overhang}    {col_DNA_Sequence[0:aa_num_former*3]}    {col_DNA_Sequence[aa_num_former*3:]}    {col_Position}    {col_Codon_bias_score}    {c}\\n\")\n",
    "        f.write(f\"\\nPrimer details:(_US means upstream; _DS means downstream)\\n\")\n",
    "        for i in primer_list:\n",
    "            f.write(f\"{i}: {primer_list[i]}\\n\") \n",
    "    loadingbar['value'] = max_generation_num+1\n",
    "    \n",
    "    \n",
    "import tkinter as tk\n",
    "import tkinter.messagebox\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "from windnd import hook_dropfiles\n",
    "from os.path import isfile\n",
    "\n",
    "aa_num_list = ['1+1','2+2','3+3','0+1','0+2','0+3','1+0','2+0','3+0']\n",
    "\n",
    "def rightside():\n",
    "    if var1.get()==0:\n",
    "        lbIN.place_forget()\n",
    "        textIN.place_forget()\n",
    "        lbMR.place_forget()\n",
    "        textMR.place_forget()\n",
    "        lbCR.place_forget()\n",
    "        textCR.place_forget()\n",
    "        lbGUL.place_forget()\n",
    "        textGUL.place_forget()\n",
    "        lbGLL.place_forget()\n",
    "        textGLL.place_forget()\n",
    "        lbCUL.place(x=660,y=120,height=30,width=200)\n",
    "        textCUL.place(x=860,y=120,height=30,width=80)\n",
    "        lbCLL.place(x=660,y=160,height=30,width=200)\n",
    "        textCLL.place(x=860,y=160,height=30,width=80)\n",
    "        biascheck.select()\n",
    "    if var1.get()==1:\n",
    "        lbIN.place_forget()\n",
    "        textIN.place_forget()\n",
    "        lbMR.place_forget()\n",
    "        textMR.place_forget()\n",
    "        lbCR.place_forget()\n",
    "        textCR.place_forget()\n",
    "        lbGUL.place_forget()\n",
    "        textGUL.place_forget()\n",
    "        lbGLL.place_forget()\n",
    "        textGLL.place_forget()\n",
    "        lbCUL.place_forget()\n",
    "        textCUL.place_forget()\n",
    "        lbCLL.place_forget()\n",
    "        textCLL.place_forget()\n",
    "        biascheck.select()\n",
    "    if var1.get()==2:\n",
    "        lbCUL.place_forget()\n",
    "        textCUL.place_forget()\n",
    "        lbCLL.place_forget()\n",
    "        textCLL.place_forget()\n",
    "        lbIN.place(x=660,y=200,height=30,width=200)\n",
    "        textIN.place(x=860,y=200,height=30,width=80)\n",
    "        lbMR.place(x=660,y=240,height=30,width=200)\n",
    "        textMR.place(x=860,y=240,height=30,width=80)\n",
    "        lbCR.place(x=660,y=280,height=30,width=200)\n",
    "        textCR.place(x=860,y=280,height=30,width=80)\n",
    "        lbGUL.place(x=660,y=120,height=30,width=200)\n",
    "        textGUL.place(x=860,y=120,height=30,width=80)\n",
    "        lbGLL.place(x=660,y=160,height=30,width=200)\n",
    "        textGLL.place(x=860,y=160,height=30,width=80)\n",
    "        biascheck.select()\n",
    "    \n",
    "def dragged_DBfiles(files):\n",
    "    msg = '\\n'.join((item.decode('gbk') for item in files))+'\\n'\n",
    "    DBtext.insert(tk.END,msg)\n",
    "\n",
    "def dragged_LRfiles(files):\n",
    "    msg = '\\n'.join((item.decode('gbk') for item in files))+'\\n'\n",
    "    textLR.insert(tk.END,msg)\n",
    "\n",
    "def dragged_DNAfiles(files):\n",
    "    msg = '\\n'.join((item.decode('gbk') for item in files))+'\\n'\n",
    "    DNAtext.insert(tk.END,msg)\n",
    "    \n",
    "def dragged_RSfiles(files):\n",
    "    msg = '\\n'.join((item.decode('gbk') for item in files))+'\\n'\n",
    "    RStext.insert(tk.END,msg)\n",
    "    \n",
    "def load_files():\n",
    "    MDbox1.delete(0,tk.END)\n",
    "    MDbox2.delete(0,tk.END)\n",
    "    files = DBtext.get('1.0',tk.END+\"-2c\")\n",
    "    if files != \"\":\n",
    "        file_list = files.split(\"\\n\")\n",
    "        while \"\" in file_list:\n",
    "            file_list.remove(\"\")\n",
    "        module_list = []\n",
    "        errors = \"\"\n",
    "        for file in file_list:\n",
    "            if isfile(file) == True:\n",
    "                module_lib = open(file) #open files\n",
    "                for line in module_lib:\n",
    "                    if line.startswith('>'):\n",
    "                        name=line.replace('>','').strip()\n",
    "                        module_list.append(name)\n",
    "                module_lib.close()\n",
    "            else:\n",
    "                errors += f\"{file}\\n\"\n",
    "        for m in module_list:\n",
    "            MDbox1.insert(tk.END, m)\n",
    "        if errors != \"\":\n",
    "            tk.messagebox.showerror('Error',f'{errors}do not exist')\n",
    "\n",
    "def add_module():\n",
    "    module = MDbox1.get(MDbox1.curselection())\n",
    "    length = MDbox2.size()+1\n",
    "    MDbox2.insert(tk.END, f\"#{length}: {module}\")\n",
    "    \n",
    "def delete_module():\n",
    "    MDbox2.delete(tk.END)\n",
    "\n",
    "def clear_module():\n",
    "    MDbox2.delete(0,tk.END)\n",
    "    \n",
    "def search_module():\n",
    "    target = SearchE.get()\n",
    "    if target == \"\":\n",
    "        MDbox1.delete(0,tk.END)\n",
    "        load_files()\n",
    "    else:\n",
    "        module_list = []\n",
    "        for module in MDbox1.get(0,tk.END):\n",
    "            if target in module:\n",
    "                module_list.append(module)\n",
    "        if module_list != []:\n",
    "            MDbox1.delete(0,tk.END)\n",
    "            for m in module_list:\n",
    "                MDbox1.insert(tk.END, m)\n",
    "    \n",
    "def clearall():\n",
    "    textSSLL.delete('1.0',tk.END)\n",
    "    textSSLL.insert(tk.END, '0.1')\n",
    "    textCUL.delete('1.0',tk.END)\n",
    "    textCUL.insert(tk.END, '50000')\n",
    "    textCLL.delete('1.0',tk.END)\n",
    "    textCLL.insert(tk.END, '10')\n",
    "    textIN.delete('1.0',tk.END)\n",
    "    textIN.insert(tk.END, '10')\n",
    "    textMR.delete('1.0',tk.END)\n",
    "    textMR.insert(tk.END, '0')\n",
    "    textCR.delete('1.0',tk.END)\n",
    "    textCR.insert(tk.END, '0')\n",
    "    textGUL.delete('1.0',tk.END)\n",
    "    textGUL.insert(tk.END, '3000')\n",
    "    textGLL.delete('1.0',tk.END)\n",
    "    textGLL.insert(tk.END, '10')\n",
    "    \n",
    "def run_algorithm(DB, DNA, RS, MD, SSLL, CUL, CLL, IN, MR, CR, GUL, GLL, AN, FT, ECB):\n",
    "    errors = \"\"\n",
    "    if DB == \"\":\n",
    "        errors += 'No protein files input\\n'\n",
    "    if DB != \"\":\n",
    "        file_list = DB.split(\"\\n\")\n",
    "        while \"\" in file_list:\n",
    "            file_list.remove(\"\")\n",
    "        for file in file_list:\n",
    "            if isfile(file) == False:\n",
    "                errors += f'{file} do not exist\\n'\n",
    "    if DNA == \"\":\n",
    "        errors += 'No DNA files input\\n'\n",
    "    if DNA != \"\":\n",
    "        DNA_file_list = DNA.split(\"\\n\")\n",
    "        while \"\" in DNA_file_list:\n",
    "            DNA_file_list.remove(\"\")\n",
    "        for file in DNA_file_list:\n",
    "            if isfile(file) == False:\n",
    "                errors += f'{file} do not exist\\n'\n",
    "    if RS == \"\":\n",
    "        errors += 'No sequence patterns file inputs\\n'\n",
    "    if RS != \"\":\n",
    "        RS_file_list = RS.split(\"\\n\")\n",
    "        while \"\" in RS_file_list:\n",
    "            RS_file_list.remove(\"\")\n",
    "        for file in RS_file_list:\n",
    "            if isfile(file) == False:\n",
    "                errors += f'{file} do not exist\\n'\n",
    "    if MD == \"\":\n",
    "        errors += 'No module inputs\\n'\n",
    "    if SSLL == \"\":\n",
    "        errors += 'No self score lower limit inputs\\n'\n",
    "    else:\n",
    "        if (float(SSLL)<0) or (float(SSLL)>=1):\n",
    "            errors += 'Self score lower limit should be in 0-1\\n'\n",
    "    if AN == \"\":\n",
    "        errors += 'No amino acid number inputs\\n'\n",
    "    if FT == \"\":\n",
    "        errors += 'No time and tempreture input\\n'\n",
    "    if var1.get()==0:\n",
    "        if CUL == \"\":\n",
    "            errors += 'No maximum cycles inputs\\n'\n",
    "        else:\n",
    "            if int(CUL) < int(CLL):\n",
    "                errors += 'Maximum cycles should be above minimum cycles inputs\\n'\n",
    "        if CLL == \"\":\n",
    "            errors += 'No minimum cycles inputs\\n'\n",
    "        else:\n",
    "            if int(CLL) == 0:\n",
    "                errors += 'Minimum cycles should be above 0\\n'\n",
    "    if var1.get()==2:\n",
    "        if IN == \"\":\n",
    "            errors += 'No initial number inputs\\n'\n",
    "        if MR == \"\":\n",
    "            errors += 'No mutation rate inputs\\n'\n",
    "        else:\n",
    "            if (float(MR)<0) or (float(MR)>1):\n",
    "                errors += 'Mutation rate should be in 0-1\\n'\n",
    "        if CR == \"\":\n",
    "            errors += 'No crossover rate inputs\\n'\n",
    "        else:\n",
    "            if (float(CR)<0) or (float(CR)>1):\n",
    "                errors += 'Crossover rate should be in 0-1\\n'\n",
    "        if GUL == \"\":\n",
    "            errors += 'No maximum generations inputs\\n'\n",
    "        else:\n",
    "            if int(GUL) < int(GLL):\n",
    "                errors += 'Maximum generations should be above minimum generations inputs\\n'\n",
    "        if GLL == \"\":\n",
    "            errors += 'No minimum generations inputs\\n'\n",
    "        else:\n",
    "            if int(GLL) == 0:\n",
    "                errors += 'Minimum generations should be above 0\\n'\n",
    "    if errors != \"\":\n",
    "        tk.messagebox.showerror('Error',f'{errors}')\n",
    "    else:\n",
    "        ovset_win = tk.Tk()\n",
    "        ovset_win.title('Overhangs')\n",
    "        sw = app.winfo_screenwidth()\n",
    "        sh = app.winfo_screenheight()\n",
    "        ww=300\n",
    "        wh=350\n",
    "        xaxis = (sw-ww) / 2-260\n",
    "        yaxis = (sh-wh) / 2\n",
    "        ovset_win.geometry('%dx%d+%d+%d'%(ww,wh,xaxis,yaxis))\n",
    "        ovset_win.resizable(False, False)\n",
    "        lbOVSET = tk.Label(ovset_win, text='Overhangs determined already', fg='black', font=('Times',14,'bold'))\n",
    "        lbOVSET.place(x=20,y=20,height=30,width=260)\n",
    "        textOVSET = tk.Text(ovset_win, bg='PowderBlue',borderwidth = 3,relief='sunken', font=('Times',14))\n",
    "        for m in range(1,len(MD)):\n",
    "            textOVSET.insert(tk.END, str(m)+'_\\n')\n",
    "        textOVSET.place(x=40,y=50,height=230,width=220)\n",
    "        scy3 = tk.Scrollbar(textOVSET,command=textOVSET.yview)\n",
    "        scy3.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        MDbox1.config(yscrollcommand=scy1.set)\n",
    "        OK = tk.Button(ovset_win, text='OK', width=10, bg='SkyBlue',fg='black',font=('Times',12), command=lambda: runnext(DB, DNA, RS, MD, SSLL, CUL, CLL, IN, MR, CR, GUL, GLL, AN, FT, ECB,\n",
    "                                                                                                                         textOVSET.get('1.0',tk.END+\"-2c\")))\n",
    "        OK.place(x=40,y=300,height=30,width=80)\n",
    "        CANCEL = tk.Button(ovset_win, text='CANCEL', width=10, bg='SkyBlue',fg='black',font=('Times',12), command=ovset_win.destroy)\n",
    "        CANCEL.place(x=180,y=300,height=30,width=80)\n",
    "        \n",
    "def runnext(DB, DNA, RS, MD, SSLL, CUL, CLL, IN, MR, CR, GUL, GLL, AN, FT, ECB, OVSET):\n",
    "    loadingwin = tk.Toplevel(app)\n",
    "    loadingwin.title('The algorithm is running...')\n",
    "    nww = 400\n",
    "    nwh =80\n",
    "    xaxis_nw = (sw-nww) / 2\n",
    "    yaxis_nw = (sh-nwh) / 2\n",
    "    loadingwin.geometry('%dx%d+%d+%d'%(nww,nwh,xaxis_nw,yaxis_nw))\n",
    "    loadingbar = ttk.Progressbar(loadingwin, length=350, mode='determinate', orient=tk.HORIZONTAL)\n",
    "    loadingbar.place(x=25, y=20)\n",
    "    loadingbar['value'] = 0\n",
    "    if var1.get()==0:\n",
    "        loadingbar['maximum'] = int(CUL)+1\n",
    "        Montecarlo(DB, DNA, RS, MD, int(CUL), int(CLL), float(SSLL), AN, FT, loadingwin, loadingbar, ECB, OVSET)\n",
    "        loadingwin.destroy()\n",
    "    if var1.get()==1:\n",
    "        loadingbar['maximum'] = len(MD)+1\n",
    "        Greedy(DB, DNA, RS, MD, float(SSLL), AN, FT, loadingwin, loadingbar, ECB, OVSET)\n",
    "        loadingwin.destroy()\n",
    "    if var1.get()==2:\n",
    "        loadingbar['maximum'] = int(GUL)+1\n",
    "        Genetic(DB, DNA, RS, MD, int(IN), float(MR), float(CR), int(GUL), int(GLL), float(SSLL), AN, FT, loadingwin, loadingbar, ECB, OVSET)\n",
    "        loadingwin.destroy()\n",
    "        \n",
    "def get_image(filename, width, height):\n",
    "    im = Image.open(filename).resize((width, height))\n",
    "    return ImageTk.PhotoImage(im)\n",
    "\n",
    "def load_record():\n",
    "    file = textLR.get('1.0',tk.END+\"-2c\")\n",
    "    if isfile(file) == True:\n",
    "        DBtext.delete('1.0',tk.END)\n",
    "        DNAtext.delete('1.0',tk.END)\n",
    "        RStext.delete('1.0',tk.END)\n",
    "        records = open(file)\n",
    "        FT_record=''\n",
    "        tablelist = ['01h_25C','01h_37C','18h_25C','18h_37C']\n",
    "        count_line = 0\n",
    "        protein_line = float('inf')\n",
    "        DNA_line = float('inf')\n",
    "        RS_line = float('inf')\n",
    "        for line in records:\n",
    "            if line.startswith('This is the result from'):\n",
    "                if line.split(' ')[5]=='Monte':\n",
    "                    rd1.select()\n",
    "                if line.split(' ')[5]=='Greedy':\n",
    "                    rd2.select()\n",
    "                if line.split(' ')[5]=='Genetic':\n",
    "                    rd3.select()\n",
    "            if line.startswith('Mostly used codons:'):\n",
    "                if line.split(': ')[-1]=='ON':\n",
    "                    biascheck.select()\n",
    "                if line.split(': ')[-1]=='OFF':\n",
    "                    biascheck.deselect()\n",
    "            if line.startswith('Residue number:'):\n",
    "                AN_record = line.split(': ')[-1][:-1]\n",
    "                comb_jnum.current(aa_num_list.index(AN_record))\n",
    "            if line.startswith('Ligation time:'):\n",
    "                FT_record += line.split(': ')[-1][:-1]\n",
    "                FT_record += '_'\n",
    "            if line.startswith('Tempreture:'):\n",
    "                FT_record += line.split(': ')[-1][:-1]\n",
    "                combST.current(tablelist.index(FT_record))\n",
    "            if line.startswith('Overhang quality limit:'):\n",
    "                SSLL_record = line.split(': ')[-1][:-1]\n",
    "                textSSLL.delete('1.0',tk.END)\n",
    "                textSSLL.insert(tk.END, SSLL_record)\n",
    "            if line.startswith('Maximum cycles:'):\n",
    "                CUL_record = line.split(': ')[-1][:-1]\n",
    "                textCUL.delete('1.0',tk.END)\n",
    "                textCUL.insert(tk.END, CUL_record)\n",
    "            if line.startswith('Minimum cycles:'):\n",
    "                CLL_record = line.split(': ')[-1][:-1]\n",
    "                textCLL.delete('1.0',tk.END)\n",
    "                textCLL.insert(tk.END, CLL_record)\n",
    "            if line.startswith('Maximum generations:'):\n",
    "                GUL_record = line.split(': ')[-1][:-1]\n",
    "                textGUL.delete('1.0',tk.END)\n",
    "                textGUL.insert(tk.END, GUL_record)\n",
    "            if line.startswith('Minimum generations:'):\n",
    "                GLL_record = line.split(': ')[-1][:-1]\n",
    "                textGLL.delete('1.0',tk.END)\n",
    "                textGLL.insert(tk.END, GLL_record)\n",
    "            if line.startswith('Initial number:'):\n",
    "                IN_record = line.split(': ')[-1][:-1]\n",
    "                textIN.delete('1.0',tk.END)\n",
    "                textIN.insert(tk.END, IN_record)            \n",
    "            if line.startswith('Mutation rate:'):\n",
    "                MR_record = line.split(': ')[-1][:-1]\n",
    "                textMR.delete('1.0',tk.END)\n",
    "                textMR.insert(tk.END, MR_record)             \n",
    "            if line.startswith('Crossover rate:'):\n",
    "                CR_record = line.split(': ')[-1][:-1]\n",
    "                textCR.delete('1.0',tk.END)\n",
    "                textCR.insert(tk.END, CR_record)\n",
    "            if line.startswith('Protein files:'):\n",
    "                protein_line = count_line\n",
    "            if (count_line>protein_line)&(line.split('.')[-1][:-1]=='fasta'):\n",
    "                DBtext.insert(tk.END, line)\n",
    "            if line.startswith('DNA files:'):\n",
    "                protein_line = float('inf')\n",
    "                DNA_line = count_line\n",
    "            if (count_line>DNA_line)&(line.split('.')[-1][:-1]=='fasta'):\n",
    "                DNAtext.insert(tk.END, line)\n",
    "            if line.startswith('Restriction sites avoided:'):\n",
    "                DNA_line = float('inf')\n",
    "                RS_line = count_line\n",
    "            if (count_line>RS_line)&(line.split('.')[-1][:-1]=='fasta'):\n",
    "                RStext.insert(tk.END, line)\n",
    "            if line.startswith('#1'):\n",
    "                load_files()\n",
    "                for module_record in line.split('  ')[:-1]:\n",
    "                    MDbox2.insert(tk.END, module_record)    \n",
    "            count_line+=1\n",
    "        rightside()\n",
    "        textLR.delete('1.0',tk.END)\n",
    "    else:\n",
    "        tk.messagebox.showerror('Error',f'{file} do not exist')\n",
    "\n",
    "#show infos\n",
    "def show_algorithm_info(event):\n",
    "    win_algorithm_info.place(x=135, y=40)\n",
    "def hide_algorithm_info(event):\n",
    "    win_algorithm_info.place_forget()\n",
    "    \n",
    "def show_biascheck_info(event):\n",
    "    win_biascheck_info.place(x=520, y=70)\n",
    "def hide_biascheck_info(event):\n",
    "    win_biascheck_info.place_forget()\n",
    "    \n",
    "def show_aa_info(event):\n",
    "    win_aa_info.place(x=195, y=120)\n",
    "def hide_aa_info(event):\n",
    "    win_aa_info.place_forget()\n",
    "\n",
    "def show_ft_info(event):\n",
    "    win_ft_info.place(x=500, y=120)\n",
    "def hide_ft_info(event):\n",
    "    win_ft_info.place_forget()\n",
    "        \n",
    "def show_file_info(event):\n",
    "    win_file_info.place(x=160, y=215)\n",
    "def hide_file_info(event):\n",
    "    win_file_info.place_forget()\n",
    "\n",
    "def show_DNAfile_info(event):\n",
    "    win_DNAfile_info.place(x=140, y=370)\n",
    "def hide_DNAfile_info(event):\n",
    "    win_DNAfile_info.place_forget()\n",
    "    \n",
    "def show_RSfile_info(event):\n",
    "    win_RSfile_info.place(x=510, y=370)\n",
    "def hide_RSfile_info(event):\n",
    "    win_RSfile_info.place_forget()    \n",
    "\n",
    "def show_module_info(event):\n",
    "    win_module_info.place(x=130, y=490)\n",
    "def hide_module_info(event):\n",
    "    win_module_info.place_forget()\n",
    "        \n",
    "def show_AP_info(event):\n",
    "    win_AP_info.place(x=450, y=40)\n",
    "def hide_AP_info(event):\n",
    "    win_AP_info.place_forget()       \n",
    "        \n",
    "def show_SSLL_info(event):\n",
    "    win_SSLL_info.place(x=370, y=80)\n",
    "def hide_SSLL_info(event):\n",
    "    win_SSLL_info.place_forget()\n",
    "        \n",
    "def show_CUL_info(event):\n",
    "    win_CUL_info.place(x=370, y=120)\n",
    "def hide_CUL_info(event):\n",
    "    win_CUL_info.place_forget()\n",
    "    \n",
    "def show_CLL_info(event):\n",
    "    win_CLL_info.place(x=370, y=160)\n",
    "def hide_CLL_info(event):\n",
    "    win_CLL_info.place_forget()\n",
    "        \n",
    "def show_IN_info(event):\n",
    "    win_IN_info.place(x=435, y=200)\n",
    "def hide_IN_info(event):\n",
    "    win_IN_info.place_forget()\n",
    "                \n",
    "def show_MR_info(event):\n",
    "    win_MR_info.place(x=505, y=240)\n",
    "def hide_MR_info(event):\n",
    "    win_MR_info.place_forget()\n",
    "\n",
    "def show_CR_info(event):\n",
    "    win_CR_info.place(x=505, y=280)\n",
    "def hide_CR_info(event):\n",
    "    win_CR_info.place_forget()\n",
    "                \n",
    "def show_GUL_info(event):\n",
    "    win_GUL_info.place(x=330, y=120)\n",
    "def hide_GUL_info(event):\n",
    "    win_GUL_info.place_forget()\n",
    "    \n",
    "def show_GLL_info(event):\n",
    "    win_GLL_info.place(x=330, y=160)\n",
    "def hide_GLL_info(event):\n",
    "    win_GLL_info.place_forget()\n",
    "    \n",
    "def show_LR_info(event):\n",
    "    win_LR_info.place(x=470, y=490)\n",
    "def hide_LR_info(event):\n",
    "    win_LR_info.place_forget()\n",
    "    \n",
    "# UI surface\n",
    "app = tk.Tk()\n",
    "app.title('Overhangs for golden gate')\n",
    "sw = app.winfo_screenwidth()\n",
    "sh = app.winfo_screenheight()\n",
    "ww=980\n",
    "wh=850\n",
    "xaxis = (sw-ww) / 2-260\n",
    "yaxis = (sh-wh) / 2\n",
    "app.geometry('%dx%d+%d+%d'%(ww,wh,xaxis,yaxis))\n",
    "app.resizable(False, False)\n",
    "\n",
    "canvas = tk.Canvas(app, width=980, height=850)\n",
    "im = get_image('appbg.jpg',980,850)\n",
    "canvas.create_image(490,425,image=im)\n",
    "canvas.pack()\n",
    "\n",
    "\n",
    "#left side\n",
    "lb1 = tk.Label(app, text='Algorithm:', fg='black', bg='PaleTurquoise', font=('Times',15,'bold'))\n",
    "lb1.place(x=40,y=40,height=30,width=95)\n",
    "\n",
    "var1 = tk.IntVar()\n",
    "rd1 = tk.Radiobutton(app,text=\"Monte Carlo\",variable=var1,value=0,font=('Times',13),borderwidth = 1, relief=\"raised\", command=rightside)\n",
    "rd1.place(x=40,y=70,height=30,width=120)\n",
    "rd2 = tk.Radiobutton(app,text=\"Greedy\",variable=var1,value=1,font=('Times',13), borderwidth = 1, relief=\"raised\",command=rightside)\n",
    "rd2.place(x=160,y=70,height=30,width=90)\n",
    "rd3 = tk.Radiobutton(app,text=\"Genetic\",variable=var1,value=2,font=('Times',13), borderwidth = 1, relief=\"raised\",command=rightside)\n",
    "rd3.place(x=250,y=70,height=30,width=90)\n",
    "\n",
    "CheckVar = tk.IntVar()\n",
    "biascheck = tk.Checkbutton(app,text='Mostly used codons',font=('Times',13),variable = CheckVar,onvalue=1,offvalue=0)\n",
    "biascheck.place(x=380,y=70)\n",
    "biascheck.select()\n",
    "\n",
    "lbjnum = tk.Label(app, text='Residue number:', fg='black', bg='PaleTurquoise', font=('Times',15,'bold'))\n",
    "lbjnum.place(x=40,y=120,height=30,width=155)\n",
    "comb_jnum = ttk.Combobox(app,values=aa_num_list,font=('Times',12), state='readonly')\n",
    "comb_jnum.place(x=40,y=150,height=30, width=200)\n",
    "\n",
    "lbST = tk.Label(app, text='Time and tempreture:', fg='black', bg='PaleTurquoise', font=('Times',15,'bold'))\n",
    "lbST.place(x=300,y=120,height=30,width=200)\n",
    "combST = ttk.Combobox(app,values=['01h_25C','01h_37C','18h_25C','18h_37C'],font=('Times',12),state='readonly')\n",
    "combST.place(x=300,y=150,height=30, width=200)\n",
    "\n",
    "style1=ttk.Style() # build style object\n",
    "style1.configure('1.TSeparator',background='black') # select background color \n",
    "sep1 = ttk.Separator(app, orient='horizontal',style='1.TSeparator')\n",
    "sep1.place(x=40,y=200,height=1,width=350)\n",
    "\n",
    "lb2 = tk.Label(app, text='Protein files:', fg='black', bg='MistyRose', font=('Times',15,'bold'))\n",
    "lb2.place(x=40,y=215,height=30,width=120)\n",
    "DBtext = tk.Text(app, bg='PowderBlue',borderwidth = 3,relief='sunken', font=('Times',13))\n",
    "DBtext.place(x=40,y=245,height=100,width=400)\n",
    "hook_dropfiles(DBtext , func=dragged_DBfiles)\n",
    "\n",
    "sep2 = ttk.Separator(app, orient='horizontal',style='1.TSeparator')\n",
    "sep2.place(x=40,y=360,height=1,width=350)\n",
    "\n",
    "lb4 = tk.Label(app, text='DNA files:', fg='black', bg='MistyRose', font=('Times',15,'bold'))\n",
    "lb4.place(x=40,y=370,height=30,width=100)\n",
    "DNAtext = tk.Text(app, bg='PowderBlue',borderwidth = 3,relief='sunken', font=('Times',13))\n",
    "DNAtext.place(x=40,y=400,height=60,width=250)\n",
    "hook_dropfiles(DNAtext , func=dragged_DNAfiles)\n",
    "\n",
    "lb5 = tk.Label(app, text='Sequence patterns file:', fg='black', bg='MistyRose', font=('Times',15,'bold'))\n",
    "lb5.place(x=310,y=370,height=30,width=200)\n",
    "RStext = tk.Text(app, bg='PowderBlue',borderwidth = 3,relief='sunken', font=('Times',13))\n",
    "RStext.place(x=310,y=400,height=60,width=250)\n",
    "hook_dropfiles(RStext , func=dragged_RSfiles)\n",
    "\n",
    "sep4 = ttk.Separator(app, orient='horizontal',style='1.TSeparator')\n",
    "sep4.place(x=40,y=475,height=1,width=350)\n",
    "\n",
    "lb3 = tk.Label(app, text='Modules:', fg='black', bg='MistyRose', font=('Times',15,'bold'))\n",
    "lb3.place(x=40,y=490,height=30,width=90)\n",
    "\n",
    "SearchE = tk.Entry(app, bg='linen',borderwidth = 3, font=('Times',12))\n",
    "SearchE.place(x=40, y=520,height=35, width=215)\n",
    "\n",
    "MDbox1 = tk.Listbox(app, bg='linen',borderwidth = 3, font=('Times',12))\n",
    "MDbox1.place(x=40,y=560,height=210,width=260)\n",
    "\n",
    "MDbox2 = tk.Listbox(app, bg='linen',borderwidth = 3, font=('Times',12))\n",
    "MDbox2.place(x=340,y=520,height=250,width=260)\n",
    "\n",
    "scy1 = tk.Scrollbar(MDbox1,command=MDbox1.yview)\n",
    "scy1.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "MDbox1.config(yscrollcommand=scy1.set)\n",
    "\n",
    "scy2 = tk.Scrollbar(MDbox2,command=MDbox2.yview)\n",
    "scy2.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "MDbox2.config(yscrollcommand=scy2.set)\n",
    "\n",
    "\n",
    "sep3 = ttk.Separator(app, orient='vertical',style='1.TSeparator')\n",
    "sep3.place(x=630,y=50,height=680,width=1)\n",
    "\n",
    "#right side\n",
    "lb6 = tk.Label(app, text='Algorithm parameters:', fg='black', bg='PaleTurquoise', font=('Times',15,'bold'))\n",
    "lb6.place(x=660,y=40,height=30,width=200)\n",
    "\n",
    "lbSSLL = tk.Label(app, text='Overhang quality limit:', fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbSSLL.place(x=660,y=80,height=30,width=200)\n",
    "textSSLL = tk.Text(app, relief='sunken',font=('Times',15,'bold'))\n",
    "textSSLL.insert(tk.END, '0.1')\n",
    "textSSLL.place(x=860,y=80,height=30,width=80)\n",
    "#self score lower limit\n",
    "\n",
    "lbCUL = tk.Label(app, text='Maximum cycles:', fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbCUL.place(x=660,y=120,height=30,width=200)\n",
    "textCUL = tk.Text(app, relief='sunken',font=('Times',15,'bold'))\n",
    "textCUL.insert(tk.END, '50000')\n",
    "textCUL.place(x=860,y=120,height=30,width=80)\n",
    "#cycle upper limit\n",
    "\n",
    "lbCLL = tk.Label(app, text='Minimum cycles:', fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbCLL.place(x=660,y=160,height=30,width=200)\n",
    "textCLL = tk.Text(app, relief='sunken',font=('Times',15,'bold'))\n",
    "textCLL.insert(tk.END, '10')\n",
    "textCLL.place(x=860,y=160,height=30,width=80)\n",
    "#cycle lower limit\n",
    "\n",
    "lbIN = tk.Label(app, text='Initial number:', fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbIN.place(x=660,y=200,height=30,width=200)\n",
    "textIN = tk.Text(app, relief='sunken',font=('Times',15,'bold'))\n",
    "textIN.insert(tk.END, '10')\n",
    "textIN.place(x=860,y=200,height=30,width=80)\n",
    "lbIN.place_forget()\n",
    "textIN.place_forget()\n",
    "#initial number\n",
    "\n",
    "lbMR = tk.Label(app, text='Mutation rate:', fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbMR.place(x=660,y=240,height=30,width=200)\n",
    "textMR = tk.Text(app, relief='sunken',font=('Times',15,'bold'))\n",
    "textMR.insert(tk.END, '0')\n",
    "textMR.place(x=860,y=240,height=30,width=80)\n",
    "lbMR.place_forget()\n",
    "textMR.place_forget()\n",
    "#mutation rate\n",
    "\n",
    "lbCR = tk.Label(app, text='Crossover rate:', fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbCR.place(x=660,y=280,height=30,width=200)\n",
    "textCR = tk.Text(app, relief='sunken',font=('Times',15,'bold'))\n",
    "textCR.insert(tk.END, '0')\n",
    "textCR.place(x=860,y=280,height=30,width=80)\n",
    "lbCR.place_forget()\n",
    "textCR.place_forget()\n",
    "#crossover rate\n",
    "\n",
    "lbGUL = tk.Label(app, text='Maximum Generations:', fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbGUL.place(x=660,y=120,height=30,width=200)\n",
    "textGUL = tk.Text(app, relief='sunken',font=('Times',15,'bold'))\n",
    "textGUL.insert(tk.END, '3000')\n",
    "textGUL.place(x=860,y=120,height=30,width=80)\n",
    "lbGUL.place_forget()\n",
    "textGUL.place_forget()\n",
    "#max_generation number\n",
    "\n",
    "lbGLL = tk.Label(app, text='Minimum Generations:', fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbGLL.place(x=660,y=160,height=30,width=200)\n",
    "textGLL = tk.Text(app, relief='sunken',font=('Times',15,'bold'))\n",
    "textGLL.insert(tk.END, '10')\n",
    "textGLL.place(x=860,y=160,height=30,width=80)\n",
    "lbGLL.place_forget()\n",
    "textGLL.place_forget()\n",
    "#min_generation number\n",
    "\n",
    "lbLR = tk.Label(app, text='Load report:',fg='black', bg='BlanchedAlmond', font=('Times',15,'bold'))\n",
    "lbLR.place(x=660, y=490,height=30,width=130)\n",
    "textLR = tk.Text(app, relief='sunken',font=('Times',13))\n",
    "textLR.place(x=660, y=520, height=50, width=210)\n",
    "hook_dropfiles(textLR , func=dragged_LRfiles)\n",
    "\n",
    "\n",
    "#buttons\n",
    "START = tk.Button(text='START', width=10, bg='SkyBlue',fg='black',font=('Times',12), command=lambda: run_algorithm(DBtext.get('1.0',tk.END+\"-2c\"),\n",
    "                                                                                                           DNAtext.get('1.0',tk.END+\"-2c\"),\n",
    "                                                                                                           RStext.get('1.0',tk.END+\"-2c\"),\n",
    "                                                                                                           MDbox2.get(0,tk.END),\n",
    "                                                                                                           textSSLL.get('1.0',tk.END+\"-1c\"),\n",
    "                                                                                                           textCUL.get('1.0',tk.END+\"-1c\"),\n",
    "                                                                                                           textCLL.get('1.0',tk.END+\"-1c\"),\n",
    "                                                                                                           textIN.get('1.0',tk.END+\"-1c\"),\n",
    "                                                                                                           textMR.get('1.0',tk.END+\"-1c\"),\n",
    "                                                                                                           textCR.get('1.0',tk.END+\"-1c\"),\n",
    "                                                                                                           textGUL.get('1.0',tk.END+\"-1c\"),\n",
    "                                                                                                           textGLL.get('1.0',tk.END+\"-1c\"),\n",
    "                                                                                                           comb_jnum.get(),\n",
    "                                                                                                           combST.get(),\n",
    "                                                                                                           CheckVar.get()\n",
    "                                                                                                           ))\n",
    "START.place(x=660,y=350,height=30,width=80)\n",
    "\n",
    "RESET = tk.Button(text='RESET', bg='SkyBlue',fg='black', font=('Times',12), command=clearall)\n",
    "RESET.place(x=760,y=350,height=30,width=80)\n",
    "\n",
    "EXIT = tk.Button(text='EXIT', bg='SkyBlue',fg='black', font=('Times',12), command=app.destroy)\n",
    "EXIT.place(x=860,y=350,height=30,width=80)\n",
    "\n",
    "LOAD = tk.Button(text='LOAD', height=4, width=10, bg='SkyBlue',fg='black',font=('Times',12), command=load_files)\n",
    "LOAD.place(x=450,y=250)\n",
    "\n",
    "ADD = tk.Button(text='ADD MODULE', height=1, width=28, bg='SkyBlue',fg='black', font=('Times',12), command=add_module)\n",
    "ADD.place(x=40,y=780)\n",
    "\n",
    "DELETE = tk.Button(text='DELETE MODULE', height=1, width=16,bg='SkyBlue',fg='black', font=('Times',12), command=delete_module)\n",
    "DELETE.place(x=340,y=780)\n",
    "\n",
    "CLEAR = tk.Button(text='CLEAR ALL', height=1, width=10, bg='SkyBlue',fg='black', font=('Times',12), command=clear_module)\n",
    "CLEAR.place(x=500,y=780)\n",
    "\n",
    "SEARCH = tk.Button(text='', height=1, width=3,bg='SkyBlue',fg='black', font=('Times',14), command=search_module)\n",
    "SEARCH.place(x=260,y=520)\n",
    "\n",
    "LOAD2 = tk.Button(text='LOAD', height=1, width=5, bg='SkyBlue',fg='black',font=('Times',12), command=load_record)\n",
    "LOAD2.place(x=880, y=530)\n",
    "\n",
    "\n",
    "#info_win\n",
    "lb1.bind(\"<Enter>\",show_algorithm_info)\n",
    "lb1.bind(\"<Leave>\",hide_algorithm_info)\n",
    "win_algorithm_info = tk.Message(app,\n",
    "                                text='Choose one algorithm:\\nMontecarlo, Greedy, or Genetic',\n",
    "                                font=('Calibri',13),\n",
    "                                relief='ridge',\n",
    "                                borderwidth = 3,\n",
    "                                width=300,\n",
    "                                bg='linen')\n",
    "\n",
    "biascheck.bind(\"<Enter>\",show_biascheck_info)\n",
    "biascheck.bind(\"<Leave>\",hide_biascheck_info)\n",
    "win_biascheck_info = tk.Message(app,\n",
    "                                text='Select this to use the more commonly used codons wherever possible',\n",
    "                                font=('Calibri',13),\n",
    "                                relief='ridge',\n",
    "                                borderwidth = 3,\n",
    "                                width=200,\n",
    "                                bg='linen')\n",
    "\n",
    "lbjnum.bind(\"<Enter>\",show_aa_info)\n",
    "lbjnum.bind(\"<Leave>\",hide_aa_info)\n",
    "win_aa_info = tk.Message(app,\n",
    "                        text='The number of residues in each junction;\\neg: 1+1 means \\nusing the last 1 residue in the former module\\n and the first 1 residue in the latter module',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=350,\n",
    "                        bg='linen')\n",
    "\n",
    "lbST.bind(\"<Enter>\",show_ft_info)\n",
    "lbST.bind(\"<Leave>\",hide_ft_info)\n",
    "win_ft_info = tk.Message(app,\n",
    "                        text='Time and tempreture for the ligation',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=200,\n",
    "                        bg='linen')\n",
    "\n",
    "lb2.bind(\"<Enter>\",show_file_info)\n",
    "lb2.bind(\"<Leave>\",hide_file_info)\n",
    "win_file_info = tk.Message(app,\n",
    "                        text='Modules protein sequence files (fasta format)',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=200,\n",
    "                        bg='linen')\n",
    "\n",
    "lb4.bind(\"<Enter>\",show_DNAfile_info)\n",
    "lb4.bind(\"<Leave>\",hide_DNAfile_info)\n",
    "win_DNAfile_info = tk.Message(app,\n",
    "                        text='Modules DNA sequence files (fasta format)',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=200,\n",
    "                        bg='linen')\n",
    "\n",
    "lb5.bind(\"<Enter>\",show_RSfile_info)\n",
    "lb5.bind(\"<Leave>\",hide_RSfile_info)\n",
    "win_RSfile_info = tk.Message(app,\n",
    "                        text='Restriction sites avoided (fasta format)',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=200,\n",
    "                        bg='linen')\n",
    "\n",
    "lb3.bind(\"<Enter>\",show_module_info)\n",
    "lb3.bind(\"<Leave>\",hide_module_info)\n",
    "win_module_info = tk.Message(app,\n",
    "                        text='All the modules are in the left box;\\nThe modules selected are in the right box',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=300,\n",
    "                        bg='linen')\n",
    "\n",
    "lb6.bind(\"<Enter>\",show_AP_info)\n",
    "lb6.bind(\"<Leave>\",hide_AP_info)\n",
    "win_AP_info = tk.Message(app,\n",
    "                        text='Parameters of the selected algorithm',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=200,\n",
    "                        bg='linen')\n",
    "\n",
    "lbSSLL.bind(\"<Enter>\",show_SSLL_info)\n",
    "lbSSLL.bind(\"<Leave>\",hide_SSLL_info)\n",
    "win_SSLL_info = tk.Message(app,\n",
    "                        text='discard the overhangs whose WatsonCrick pairings quality is below this percentage (01)',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=300,\n",
    "                        bg='linen')\n",
    "\n",
    "lbCUL.bind(\"<Enter>\",show_CUL_info)\n",
    "lbCUL.bind(\"<Leave>\",hide_CUL_info)\n",
    "win_CUL_info = tk.Message(app,\n",
    "                        text='The maximum cycles in this algorithm;\\nDefault value is 50000',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=300,\n",
    "                        bg='linen')\n",
    "\n",
    "lbCLL.bind(\"<Enter>\",show_CLL_info)\n",
    "lbCLL.bind(\"<Leave>\",hide_CLL_info)\n",
    "win_CLL_info = tk.Message(app,\n",
    "                        text='The minimum cycles in this algorithm;\\nDefault value is 10',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=300,\n",
    "                        bg='linen')\n",
    "\n",
    "lbIN.bind(\"<Enter>\",show_IN_info)\n",
    "lbIN.bind(\"<Leave>\",hide_IN_info)\n",
    "win_IN_info = tk.Message(app,\n",
    "                        text='The initial individual number;\\nDefault value is 10',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=300,\n",
    "                        bg='linen')\n",
    "\n",
    "lbMR.bind(\"<Enter>\",show_MR_info)\n",
    "lbMR.bind(\"<Leave>\",hide_MR_info)\n",
    "win_MR_info = tk.Message(app,\n",
    "                        text='The mutation rate;\\nDefault value is 0',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=300,\n",
    "                        bg='linen')\n",
    "\n",
    "lbCR.bind(\"<Enter>\",show_CR_info)\n",
    "lbCR.bind(\"<Leave>\",hide_CR_info)\n",
    "win_CR_info = tk.Message(app,\n",
    "                        text='The crossover rate;\\nDefault value is 0',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=300,\n",
    "                        bg='linen')\n",
    "\n",
    "lbGUL.bind(\"<Enter>\",show_GUL_info)\n",
    "lbGUL.bind(\"<Leave>\",hide_GUL_info)\n",
    "win_GUL_info = tk.Message(app,\n",
    "                        text='The maximum generations in this algorithm;\\nDefault value is 3000',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=400,\n",
    "                        bg='linen')\n",
    "\n",
    "lbGLL.bind(\"<Enter>\",show_GLL_info)\n",
    "lbGLL.bind(\"<Leave>\",hide_GLL_info)\n",
    "win_GLL_info = tk.Message(app,\n",
    "                        text='The minimum generations in this algorithm;\\nDefault value is 10',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=400,\n",
    "                        bg='linen')\n",
    "\n",
    "lbLR.bind(\"<Enter>\",show_LR_info)\n",
    "lbLR.bind(\"<Leave>\",hide_LR_info)\n",
    "win_LR_info = tk.Message(app,\n",
    "                        text='reload the arguments in a result file',\n",
    "                        font=('Calibri',13),\n",
    "                        relief='ridge',\n",
    "                        borderwidth = 3,\n",
    "                        width=180,\n",
    "                        bg='linen')\n",
    "\n",
    "tk.mainloop()\n",
    "\n",
    "#output this as an exe file:\n",
    "#pyinstaller -F -w -i appicon.ico Overhangs_tool.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c832315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
